{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import docker \n",
    "import pandas as pd\n",
    "import tensorflow as tf\n",
    "from gym_torcs_docker import TorcsDockerEnv, obs_to_state\n",
    "from ddpg import DDPG\n",
    "from a3c import A3C\n",
    "\n",
    "docker_client = docker.from_env()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [],
   "source": [
    "def testModelOnTrack(\n",
    "        docker_client, sess, model, trackname, max_steps=1000,\n",
    "        docker_port=3101):\n",
    "    \"\"\"Drives the model around the specified track for 1000 time steps\"\"\"\n",
    "\n",
    "    env = TorcsDockerEnv(\n",
    "        docker_client, 'test', port=docker_port)\n",
    "    observation = env.reset(relaunch=True)\n",
    "    state_t = obs_to_state(observation)\n",
    "\n",
    "    results = {}\n",
    "\n",
    "    for i in range(max_steps):\n",
    "        action_t = model.predict(sess, state_t.reshape(1, state_t.shape[0]))\n",
    "        observation, reward_t, done, _ = env.step(action_t[0])\n",
    "        state_t = obs_to_state(observation)\n",
    "        results[i] = reward_t\n",
    "        if done:\n",
    "            break\n",
    "\n",
    "    env.end()\n",
    "\n",
    "    return results\n",
    "\n",
    "def testDDPG(docker_client, modeldir, test_tracks):\n",
    "    \"\"\"Loads the weights from the model dir and drives the agent around the provided test tracks\"\"\"\n",
    "    config = tf.ConfigProto()\n",
    "    config.gpu_options.allow_growth = True\n",
    "    \n",
    "    tf.reset_default_graph()\n",
    "\n",
    "    model = DDPG(docker_client)\n",
    "\n",
    "    saver = tf.train.Saver(max_to_keep=5)\n",
    "    rewards = {}\n",
    "    with tf.Session(config=config) as sess:\n",
    "        ckpt = tf.train.get_checkpoint_state(modeldir)\n",
    "        saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "        \n",
    "        for track in test_tracks:\n",
    "            reward = testModelOnTrack(\n",
    "                docker_client, sess, model.actor, track, max_steps=1000,\n",
    "                docker_port=3121)\n",
    "            rewards[track] = reward\n",
    "    return rewards"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "test_tracks = ['g-track-3', 'e-track-6', 'alpine-2']\n",
    "\n",
    "path_ddpg_ref = '../models/ddpg_ref'\n",
    "path_ddpg_1 = '../models/ddpg_1'\n",
    "path_ddpg_2 = '../models/ddpg_2'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "INFO:tensorflow:Restoring parameters from ../models/ddpg_ref/model-1050.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-25 01:09:43,501] Restoring parameters from ../models/ddpg_ref/model-1050.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "-0.0518008636786\n",
      "0.462160325397\n",
      "1.11785491013\n",
      "1.66566063166\n",
      "2.00558318522\n",
      "2.46476364583\n",
      "2.68544453634\n",
      "3.00793015649\n",
      "3.25467007017\n",
      "3.48848456451\n",
      "3.62390686869\n",
      "3.55512679125\n",
      "3.67335994301\n",
      "3.54946736122\n",
      "3.51483001354\n",
      "3.28886603451\n",
      "3.12534135927\n",
      "2.88665936327\n",
      "2.55117902034\n",
      "2.23389734054\n",
      "1.90482252849\n",
      "1.55112077925\n",
      "1.19154577747\n",
      "0.827728243918\n",
      "0.43350507896\n",
      "0.0513089230392\n",
      "-0.327558419339\n",
      "-0.70684920611\n",
      "-1.0613514367\n",
      "-1.41003149142\n",
      "-1.72248503749\n",
      "-2.05891296285\n",
      "-2.39063411768\n",
      "-2.68772014806\n",
      "-2.92322908522\n",
      "-3.13159963831\n",
      "-3.38116760762\n",
      "-3.48844272593\n",
      "-3.73515456106\n",
      "-3.83965057713\n",
      "-3.87921706407\n",
      "-3.98104878571\n",
      "-4.04814462109\n",
      "-4.10673381768\n",
      "-4.16902851932\n",
      "-4.25179890045\n",
      "-4.22574613674\n",
      "-4.21480686854\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "-0.0518008636786\n",
      "0.462160325397\n",
      "1.11785491013\n",
      "1.66566063166\n",
      "2.00558318522\n",
      "2.46476364583\n",
      "2.68544453634\n",
      "3.00793015649\n",
      "3.25467007017\n",
      "3.48848456451\n",
      "3.62390686869\n",
      "3.55512679125\n",
      "3.67335994301\n",
      "3.54946736122\n",
      "3.51483001354\n",
      "3.28886603451\n",
      "3.12534135927\n",
      "2.88665936327\n",
      "2.55117902034\n",
      "2.23389734054\n",
      "1.90482252849\n",
      "1.55112077925\n",
      "1.19154577747\n",
      "0.827728243918\n",
      "0.43350507896\n",
      "0.0513089230392\n",
      "-0.327558419339\n",
      "-0.70684920611\n",
      "-1.0613514367\n",
      "-1.41003149142\n",
      "-1.72248503749\n",
      "-2.05891296285\n",
      "-2.39063411768\n",
      "-2.68772014806\n",
      "-2.92322908522\n",
      "-3.13159963831\n",
      "-3.38116760762\n",
      "-3.48844272593\n",
      "-3.73515456106\n",
      "-3.83965057713\n",
      "-3.87921706407\n",
      "-3.98104878571\n",
      "-4.04814462109\n",
      "-4.10673381768\n",
      "-4.16902851932\n",
      "-4.25179890045\n",
      "-4.22574613674\n",
      "-4.21480686854\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "-0.0518008636786\n",
      "0.462160325397\n",
      "1.11785491013\n",
      "1.66566063166\n",
      "2.00558318522\n",
      "2.46476364583\n",
      "2.68544453634\n",
      "3.00793015649\n",
      "3.25467007017\n",
      "3.48848456451\n",
      "3.62390686869\n",
      "3.55512679125\n",
      "3.67335994301\n",
      "3.54946736122\n",
      "3.51483001354\n",
      "3.28886603451\n",
      "3.12534135927\n",
      "2.88665936327\n",
      "2.55117902034\n",
      "2.23389734054\n",
      "1.90482252849\n",
      "1.55112077925\n",
      "1.19154577747\n",
      "0.827728243918\n",
      "0.43350507896\n",
      "0.0513089230392\n",
      "-0.327558419339\n",
      "-0.70684920611\n",
      "-1.0613514367\n",
      "-1.41003149142\n",
      "-1.72248503749\n",
      "-2.05891296285\n",
      "-2.39063411768\n",
      "-2.68772014806\n",
      "-2.92322908522\n",
      "-3.13159963831\n",
      "-3.38116760762\n",
      "-3.48844272593\n",
      "-3.73515456106\n",
      "-3.83965057713\n",
      "-3.87921706407\n",
      "-3.98104878571\n",
      "-4.04814462109\n",
      "-4.10673381768\n",
      "-4.16902851932\n",
      "-4.25179890045\n",
      "-4.22574613674\n",
      "-4.21480686854\n",
      "INFO:tensorflow:Restoring parameters from ../models/ddpg_1/model-1500.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-25 01:10:27,459] Restoring parameters from ../models/ddpg_1/model-1500.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0667227665861\n",
      "3.62131587604\n",
      "7.01162036027\n",
      "10.6361828457\n",
      "15.1852651759\n",
      "20.4875608672\n",
      "27.8021119789\n",
      "37.3603630786\n",
      "50.0188637449\n",
      "61.2112241484\n",
      "60.0514829069\n",
      "53.679613135\n",
      "-1\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0667227665861\n",
      "3.62131587604\n",
      "7.01162036027\n",
      "10.6361828457\n",
      "15.1852651759\n",
      "20.4875608672\n",
      "27.8021119789\n",
      "37.3603630786\n",
      "50.0188637449\n",
      "61.2112241484\n",
      "60.0514829069\n",
      "53.679613135\n",
      "-1\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0667227665861\n",
      "3.62131587604\n",
      "7.01162036027\n",
      "10.6361828457\n",
      "15.1852651759\n",
      "20.4875608672\n",
      "27.8021119789\n",
      "37.3603630786\n",
      "50.0188637449\n",
      "61.2112241484\n",
      "60.0514829069\n",
      "53.679613135\n",
      "-1\n",
      "INFO:tensorflow:Restoring parameters from ../models/ddpg_2/model-50.cptk\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[2017-04-25 01:10:50,301] Restoring parameters from ../models/ddpg_2/model-50.cptk\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0261045580767\n",
      "-0.0102201560524\n",
      "-0.0294879900407\n",
      "-0.0487919776399\n",
      "-0.0704089725615\n",
      "-0.0397596597135\n",
      "0.0634327982946\n",
      "0.0605749034372\n",
      "-0.0341220580022\n",
      "0.15063838136\n",
      "0.0973521854389\n",
      "-0.158853171716\n",
      "0.0879423783027\n",
      "0.0641925737671\n",
      "0.0579555624853\n",
      "-0.0380781989406\n",
      "0.000885729610161\n",
      "0.0231812188844\n",
      "-0.0138508599454\n",
      "-0.113027753436\n",
      "0.11563010036\n",
      "0.131191365517\n",
      "0.0334778975357\n",
      "-0.0499416719027\n",
      "-0.0504727471717\n",
      "0.0818693562108\n",
      "0.0634227709819\n",
      "0.108014323982\n",
      "-0.0617158057752\n",
      "0.0294008813904\n",
      "0.00995403574983\n",
      "0.0112739439071\n",
      "-0.0496918475209\n",
      "0.0905171366811\n",
      "-0.0106886921222\n",
      "-0.0263080547632\n",
      "0.0206184009238\n",
      "-0.00027281484261\n",
      "-0.0710100109024\n",
      "0.0222513792474\n",
      "0.00259178833912\n",
      "-0.0915697821405\n",
      "0.0373169378338\n",
      "-0.0124320755627\n",
      "0.0502701388619\n",
      "-0.0434995790951\n",
      "0.0272631135221\n",
      "0.056993846235\n",
      "-0.00161666531499\n",
      "0.0503090782031\n",
      "0.0676896042599\n",
      "0.00807991167012\n",
      "-0.0499147665219\n",
      "0.0562766388331\n",
      "0.0648560645717\n",
      "-0.082979254255\n",
      "-0.110940485552\n",
      "0.0597141272085\n",
      "0.176876922459\n",
      "-0.0226459528275\n",
      "-0.0659625449276\n",
      "0.0333387372552\n",
      "0.0312019202921\n",
      "0.0584501063513\n",
      "-0.00436251867216\n",
      "0.0673261289653\n",
      "-0.0434374599044\n",
      "-0.125113725538\n",
      "-0.0732799984175\n",
      "-0.0747084737947\n",
      "-0.102038029842\n",
      "0.00355325842376\n",
      "0.01888726729\n",
      "-0.147017695018\n",
      "-0.133337166303\n",
      "-0.0424248527173\n",
      "-0.0417432314117\n",
      "-0.0314790700606\n",
      "-0.0540641908681\n",
      "0.0282683559015\n",
      "-0.0862164154603\n",
      "-0.00834853787064\n",
      "-0.150384916197\n",
      "-0.0577978833839\n",
      "-0.0530990253785\n",
      "-0.20119639925\n",
      "-0.0271740257072\n",
      "-0.014373212398\n",
      "-0.128246730051\n",
      "-0.0903038101332\n",
      "-0.0801494874283\n",
      "-0.082197023855\n",
      "-0.0184852770658\n",
      "-0.103538320953\n",
      "0.0193353649758\n",
      "-0.147361810766\n",
      "-0.0413388711031\n",
      "-0.133856615366\n",
      "-0.115322784261\n",
      "-0.0687800659394\n",
      "-0.0678852056436\n",
      "-0.0950108492499\n",
      "-0.151855699878\n",
      "-0.116000180845\n",
      "-0.137444616303\n",
      "-0.101798142347\n",
      "-0.0751892790984\n",
      "-0.119220898509\n",
      "-0.102057700431\n",
      "-0.0918074884715\n",
      "-0.160667647144\n",
      "-0.0757229761096\n",
      "-0.151583227722\n",
      "-0.0667266050986\n",
      "-0.175127273373\n",
      "-0.157816697686\n",
      "-0.12003439127\n",
      "-0.162715277644\n",
      "-0.0339042243296\n",
      "-0.164574889371\n",
      "-0.0479830554205\n",
      "-0.21957798877\n",
      "-0.231780813831\n",
      "-0.191258602926\n",
      "-0.12560959614\n",
      "-0.187600921762\n",
      "-0.107764886455\n",
      "-0.0895962059202\n",
      "-0.160770277442\n",
      "-0.184974118142\n",
      "-0.152577613749\n",
      "-0.12697851948\n",
      "-0.0527438301518\n",
      "-0.0768251931972\n",
      "-0.134319866176\n",
      "-0.163005951579\n",
      "-0.0622083689658\n",
      "-0.173537860591\n",
      "-0.128074628474\n",
      "-0.172617211086\n",
      "-0.141942507287\n",
      "-0.174734614074\n",
      "-0.170827551382\n",
      "-0.128528374965\n",
      "-0.178000792603\n",
      "-0.0871815664167\n",
      "-0.163309826131\n",
      "-0.0751049237549\n",
      "-0.0744156229137\n",
      "-0.201634894645\n",
      "-0.123435102835\n",
      "-0.136036562659\n",
      "-0.117552109419\n",
      "-0.11668140224\n",
      "-0.125534573107\n",
      "-0.228159256331\n",
      "-0.16296077257\n",
      "-0.125278865794\n",
      "-0.148483310656\n",
      "-0.306358644745\n",
      "-0.160264673527\n",
      "-0.227137060595\n",
      "-0.182613378722\n",
      "-0.257735551908\n",
      "-0.167565704911\n",
      "-0.178319715406\n",
      "-0.168357831276\n",
      "-0.10230034322\n",
      "-0.187114011275\n",
      "-0.215919752804\n",
      "-0.220728921708\n",
      "-0.234585949604\n",
      "-0.331683499535\n",
      "-0.166238999903\n",
      "-0.141702947635\n",
      "-0.266123228204\n",
      "-0.218558626011\n",
      "-0.184872791511\n",
      "-0.205020610442\n",
      "-0.198595102158\n",
      "-0.231787057055\n",
      "-0.300484641219\n",
      "-0.177548571972\n",
      "-0.239873528109\n",
      "-0.22576128679\n",
      "-0.176161246406\n",
      "-0.290913311981\n",
      "-0.120483801628\n",
      "-0.187026760245\n",
      "-0.308719141377\n",
      "-0.180623555222\n",
      "-0.352995340046\n",
      "-0.273032693624\n",
      "-0.172472481334\n",
      "-0.350068121522\n",
      "-0.235798705463\n",
      "-0.195623196778\n",
      "-0.290311491854\n",
      "-0.269151918869\n",
      "-0.271001655744\n",
      "-0.243221928197\n",
      "-0.322723570994\n",
      "-0.389705064197\n",
      "-0.307286891766\n",
      "-0.298230400898\n",
      "-0.27939707942\n",
      "-0.437869829224\n",
      "-0.35830729494\n",
      "-0.34767505113\n",
      "-0.375654615816\n",
      "-0.359505067743\n",
      "-0.456812970812\n",
      "-0.488417732765\n",
      "-0.408858276551\n",
      "-0.499438689006\n",
      "-0.582342832907\n",
      "-0.508783439743\n",
      "-0.556189848311\n",
      "-0.523426637515\n",
      "-0.529444810134\n",
      "-0.640919469779\n",
      "-0.552953641725\n",
      "-0.643921400715\n",
      "-0.619419242514\n",
      "-0.613385802816\n",
      "-0.593081472818\n",
      "-0.595834403186\n",
      "-0.612520747739\n",
      "-0.608743035859\n",
      "-0.642564702478\n",
      "-0.737601923059\n",
      "-0.694920559947\n",
      "-0.576795432781\n",
      "-0.700221021306\n",
      "-0.600493701097\n",
      "-0.666419729919\n",
      "-0.660001294835\n",
      "-0.590314088548\n",
      "-0.64534893683\n",
      "-0.632624513651\n",
      "-0.637421370732\n",
      "-0.808336757187\n",
      "-0.683920226888\n",
      "-0.735222123636\n",
      "-0.60850281371\n",
      "-0.761171518777\n",
      "-0.629677308942\n",
      "-0.737539018504\n",
      "-0.740911082386\n",
      "-0.779514941333\n",
      "-0.677772701134\n",
      "-0.731831379489\n",
      "-0.79829347431\n",
      "-0.638338119809\n",
      "-0.788453803783\n",
      "-0.871604262406\n",
      "-0.741482478038\n",
      "-0.799597513677\n",
      "-0.811017064033\n",
      "-0.765197511826\n",
      "-0.911843640391\n",
      "-0.793786827577\n",
      "-0.75498109072\n",
      "-0.800947246207\n",
      "-0.747802853783\n",
      "-0.704642629039\n",
      "-0.774454557856\n",
      "-0.805682331995\n",
      "-0.867225141788\n",
      "-0.82292752945\n",
      "-0.84253916633\n",
      "-0.75439325094\n",
      "-0.829074709215\n",
      "-0.759318871253\n",
      "-0.753517708329\n",
      "-0.8112421626\n",
      "-0.783980261736\n",
      "-0.841856276857\n",
      "-0.728737319545\n",
      "-0.837892464117\n",
      "-0.758057305317\n",
      "-0.75847520483\n",
      "-0.725928129338\n",
      "-0.78960652254\n",
      "-0.793850347655\n",
      "-0.887054653578\n",
      "-0.791419264775\n",
      "-0.841757070898\n",
      "-0.715463986245\n",
      "-0.757341666421\n",
      "-0.65802170796\n",
      "-0.852375555161\n",
      "-0.688117678165\n",
      "-0.827104000893\n",
      "-0.636039608234\n",
      "-0.693939741732\n",
      "-0.81220150319\n",
      "-0.705842095504\n",
      "-0.667319283521\n",
      "-0.805768306462\n",
      "-0.839192462972\n",
      "-0.745715630834\n",
      "-0.778786080794\n",
      "-0.61753379248\n",
      "-0.759660618578\n",
      "-0.780318170439\n",
      "-0.776861568898\n",
      "-0.692302019173\n",
      "-0.667784783108\n",
      "-0.73172947999\n",
      "-0.732865192842\n",
      "-0.680179922289\n",
      "-0.706380815356\n",
      "-0.637539296187\n",
      "-0.635796350982\n",
      "-0.583139271279\n",
      "-0.626802950792\n",
      "-0.496563345795\n",
      "-0.532113137528\n",
      "-0.55373152012\n",
      "-0.391311626227\n",
      "-0.416820374105\n",
      "-0.62317175525\n",
      "-0.491924083348\n",
      "-0.522166098924\n",
      "-0.501379343992\n",
      "-0.340412644466\n",
      "-0.42515827578\n",
      "-0.457972507371\n",
      "-0.361942884244\n",
      "-0.474876987334\n",
      "-0.45403278877\n",
      "-0.488686193805\n",
      "-0.341320721217\n",
      "-0.422759957821\n",
      "-0.335561059239\n",
      "-0.430109029785\n",
      "-0.295242981291\n",
      "-0.316521236984\n",
      "-0.403725489326\n",
      "-0.376374339647\n",
      "-0.323561719279\n",
      "-0.270307105188\n",
      "-0.373081683761\n",
      "-0.391097611383\n",
      "-0.35912436993\n",
      "-0.426699654503\n",
      "-0.405463192901\n",
      "-0.345144222467\n",
      "-0.335298525333\n",
      "-0.244175207207\n",
      "-0.217160973596\n",
      "-0.310948498296\n",
      "-0.327548453166\n",
      "-0.277845816153\n",
      "-0.27943873946\n",
      "-0.181960370515\n",
      "-0.289371575616\n",
      "-0.203620687091\n",
      "-0.239194179221\n",
      "-0.320852152048\n",
      "-0.334312176997\n",
      "-0.322387084221\n",
      "-0.329929107361\n",
      "-0.156042230521\n",
      "-0.264347270408\n",
      "-0.290475243833\n",
      "-0.177813564998\n",
      "-0.196463546396\n",
      "-0.235479987638\n",
      "-0.207414938815\n",
      "-0.296545769031\n",
      "-0.198057770168\n",
      "-0.172103865754\n",
      "-0.231994598633\n",
      "-0.216052579954\n",
      "-0.197237332359\n",
      "-0.222532621408\n",
      "-0.201240781491\n",
      "-0.273948827673\n",
      "-0.26285460481\n",
      "-0.218249933029\n",
      "-0.204661284877\n",
      "-0.217468326417\n",
      "-0.221676195925\n",
      "-0.184420139822\n",
      "-0.180947583699\n",
      "-0.244700510513\n",
      "-0.29700651687\n",
      "-0.198459625838\n",
      "-0.152288242339\n",
      "-0.145370266462\n",
      "-0.0636701816318\n",
      "-0.227284970395\n",
      "-0.105538690812\n",
      "-0.272507152891\n",
      "-0.22222757552\n",
      "-0.185501934216\n",
      "-0.187628119605\n",
      "-0.186827458522\n",
      "-0.278191631525\n",
      "-0.250264087951\n",
      "-0.217913088884\n",
      "-0.220282395448\n",
      "-0.208323188876\n",
      "-0.25144546907\n",
      "-0.223646308072\n",
      "-0.177082287449\n",
      "-0.325676279319\n",
      "-0.285579519685\n",
      "-0.297319615019\n",
      "-0.256230830959\n",
      "-0.183699882918\n",
      "-0.185926024177\n",
      "-0.317502756457\n",
      "-0.183394885907\n",
      "-0.225342370428\n",
      "-0.263725676146\n",
      "-0.293218405355\n",
      "-0.330146239012\n",
      "-0.404100609917\n",
      "-0.255255776287\n",
      "-0.270531275269\n",
      "-0.323229594251\n",
      "-0.346100253992\n",
      "-0.308588350468\n",
      "-0.330688439968\n",
      "-0.375285251204\n",
      "-0.503317942958\n",
      "-0.234284636856\n",
      "-0.489834871052\n",
      "-0.426757755725\n",
      "-0.319680083347\n",
      "-0.433702263415\n",
      "-0.525012075304\n",
      "-0.475606389219\n",
      "-0.349245872961\n",
      "-0.380135066253\n",
      "-0.503301383692\n",
      "-0.510329223815\n",
      "-0.494132621252\n",
      "-0.58754057143\n",
      "-0.429601326232\n",
      "-0.550165002402\n",
      "-0.566421073563\n",
      "-0.537383375457\n",
      "-0.504047160098\n",
      "-0.686386349047\n",
      "-0.586600422257\n",
      "-0.57625599629\n",
      "-0.690162917053\n",
      "-0.684319415074\n",
      "-0.583859830049\n",
      "-0.616619794297\n",
      "-0.658098831378\n",
      "-0.591641565674\n",
      "-0.531121775841\n",
      "-0.472919773716\n",
      "-0.627885679346\n",
      "-0.757530603158\n",
      "-0.532943586865\n",
      "-0.638449309719\n",
      "-0.648598893452\n",
      "-0.58819913261\n",
      "-0.594799301777\n",
      "-0.45193999837\n",
      "-0.650978822002\n",
      "-0.557047266934\n",
      "-0.459056625839\n",
      "-0.541781807142\n",
      "-0.609019694427\n",
      "-0.711417109021\n",
      "-0.52030667962\n",
      "-0.560842414997\n",
      "-0.641165145483\n",
      "-0.658093052763\n",
      "-0.47218093858\n",
      "-0.533105662663\n",
      "-0.589188729236\n",
      "-0.632323299352\n",
      "-0.525999109268\n",
      "-0.469757136728\n",
      "-0.557152983208\n",
      "-0.526086224208\n",
      "-0.407276696834\n",
      "-0.555714752994\n",
      "-0.458473328209\n",
      "-0.524359812195\n",
      "-0.42634951661\n",
      "-0.590002330031\n",
      "-0.451580902122\n",
      "-0.432275345351\n",
      "-0.431699926614\n",
      "-0.247108969262\n",
      "-0.345117734792\n",
      "-0.331562574044\n",
      "-0.269067520587\n",
      "-0.288035396654\n",
      "-0.251294711428\n",
      "-0.248645048937\n",
      "-0.0812751041194\n",
      "-0.212610841724\n",
      "-0.129499076909\n",
      "-0.0694675546361\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.0600010237216\n",
      "-0.226715656334\n",
      "-0.0767196848724\n",
      "-0.021951124959\n",
      "-0.0896742863622\n",
      "-0.0647547311322\n",
      "-0.060667466341\n",
      "-0.246804806701\n",
      "-0.131500434603\n",
      "-0.0668066662817\n",
      "-0.215093657619\n",
      "-0.0975283688607\n",
      "-0.130489061151\n",
      "-0.0155703003251\n",
      "-0.178583769005\n",
      "-0.108310630601\n",
      "-0.152799334773\n",
      "-0.107285257658\n",
      "-0.210478194948\n",
      "-0.177646039592\n",
      "-0.163672041975\n",
      "-0.108246584961\n",
      "-0.210421268242\n",
      "-0.103668204772\n",
      "-0.0859707467195\n",
      "-0.0966087512844\n",
      "-0.066960141529\n",
      "-0.245415269366\n",
      "-0.272874562317\n",
      "-0.216781209083\n",
      "-0.210303093684\n",
      "-0.245255233304\n",
      "-0.230424208084\n",
      "-0.148399291687\n",
      "-0.33250442117\n",
      "-0.185308809153\n",
      "-0.153499293804\n",
      "-0.108633308134\n",
      "-0.130218211946\n",
      "-0.183028199194\n",
      "-0.224040504092\n",
      "-0.131275187489\n",
      "-0.238371887912\n",
      "-0.17656808091\n",
      "-0.246852139832\n",
      "-0.246751090753\n",
      "-0.136067337111\n",
      "-0.0691251086642\n",
      "-0.152733610216\n",
      "-0.136566022346\n",
      "-0.239023420009\n",
      "-0.34803298021\n",
      "-0.237013491654\n",
      "-0.247701254607\n",
      "-0.172303004675\n",
      "-0.315230470546\n",
      "-0.237255572499\n",
      "-0.291579945301\n",
      "-0.195635577321\n",
      "-0.381962939003\n",
      "-0.247490652556\n",
      "-0.392046407511\n",
      "-0.288113556962\n",
      "-0.223813793884\n",
      "-0.23760244534\n",
      "-0.275438828933\n",
      "-0.33638927025\n",
      "-0.321383183992\n",
      "-0.33156749879\n",
      "-0.410286721682\n",
      "-0.486703817874\n",
      "-0.294717126268\n",
      "-0.314910564324\n",
      "-0.411609321453\n",
      "-0.346279920654\n",
      "-0.453801970234\n",
      "-0.398328049825\n",
      "-0.486833636745\n",
      "-0.423374265131\n",
      "-0.475989602791\n",
      "-0.43067090479\n",
      "-0.517687051151\n",
      "-0.417603477338\n",
      "-0.385217126732\n",
      "-0.505585390735\n",
      "-0.584237710717\n",
      "-0.393184077866\n",
      "-0.454009999353\n",
      "-0.443828053034\n",
      "-0.454826037074\n",
      "-0.458574901383\n",
      "-0.360990508414\n",
      "-0.541316866419\n",
      "-0.370900800137\n",
      "-0.453525000543\n",
      "-0.488150645916\n",
      "-0.50294730143\n",
      "-0.460273943754\n",
      "-0.539937129665\n",
      "-0.451346687702\n",
      "-0.516539473605\n",
      "-0.558107738008\n",
      "-0.54730738425\n",
      "-0.522629068854\n",
      "-0.484970510223\n",
      "-0.376272940456\n",
      "-0.561985664138\n",
      "-0.454207393865\n",
      "-0.416289527898\n",
      "-0.560512365834\n",
      "-0.5146679523\n",
      "-0.549366361292\n",
      "-0.640937463085\n",
      "-0.531118097146\n",
      "-0.542099380284\n",
      "-0.537745916765\n",
      "-0.587132451789\n",
      "-0.555114424778\n",
      "-0.400587580766\n",
      "-0.52858707794\n",
      "-0.460860650557\n",
      "-0.552419531704\n",
      "-0.59212571376\n",
      "-0.636097752378\n",
      "-0.499965888045\n",
      "-0.550838712701\n",
      "-0.617618622792\n",
      "-0.526094033049\n",
      "-0.56897343362\n",
      "-0.648060623224\n",
      "-0.592427039067\n",
      "-0.469061405352\n",
      "-0.619142262168\n",
      "-0.525375518045\n",
      "-0.480975743363\n",
      "-0.610725951482\n",
      "-0.56714670436\n",
      "-0.62401834139\n",
      "-0.577055737801\n",
      "-0.621985279321\n",
      "-0.532946666214\n",
      "-0.707404159449\n",
      "-0.670331272539\n",
      "-0.596423114497\n",
      "-0.685899004853\n",
      "-0.652773674152\n",
      "-0.646763982809\n",
      "-0.523262691731\n",
      "-0.629901349017\n",
      "-0.600554442768\n",
      "-0.594051497477\n",
      "-0.585924915997\n",
      "-0.556603570048\n",
      "-0.582896314427\n",
      "-0.573492105411\n",
      "-0.594189377212\n",
      "-0.591082020705\n",
      "-0.503961040592\n",
      "-0.606767363945\n",
      "-0.555795299428\n",
      "-0.590365033732\n",
      "-0.590687014043\n",
      "-0.628544011044\n",
      "-0.483790014033\n",
      "-0.589580085703\n",
      "-0.704036432981\n",
      "-0.519911665139\n",
      "-0.615384391849\n",
      "-0.555978624194\n",
      "-0.588419422391\n",
      "-0.581538836579\n",
      "-0.539496651279\n",
      "-0.632951775571\n",
      "-0.497288704817\n",
      "-0.518002328491\n",
      "-0.54067017973\n",
      "-0.579406452441\n",
      "-0.549483224014\n",
      "-0.413082018342\n",
      "-0.512516339584\n",
      "-0.529619480948\n",
      "-0.425171678248\n",
      "-0.449209866026\n",
      "-0.414174049734\n",
      "-0.519430589207\n",
      "-0.361948663049\n",
      "-0.427570500858\n",
      "-0.448369877211\n",
      "-0.394914911062\n",
      "-0.371243138634\n",
      "-0.338715990281\n",
      "-0.32489398376\n",
      "-0.265799330373\n",
      "-0.354574040298\n",
      "-0.329106114083\n",
      "-0.31180474394\n",
      "-0.201234558596\n",
      "-0.288986340294\n",
      "-0.26762972278\n",
      "-0.181593211644\n",
      "-0.204525277753\n",
      "-0.158134747665\n",
      "-0.172260791725\n",
      "-0.122857708562\n",
      "-0.262416063071\n",
      "-0.184033360687\n",
      "-0.0988497429126\n",
      "-0.154753689926\n",
      "-0.133134444968\n",
      "-0.254216533253\n",
      "-0.246841308335\n",
      "-0.14815402454\n",
      "-0.257067613858\n",
      "-0.156381986282\n",
      "-0.261229987431\n",
      "-0.275259582355\n",
      "-0.160777041912\n",
      "-0.227088257009\n",
      "-0.191636435267\n",
      "-0.178230505556\n",
      "-0.147320811671\n",
      "-0.16367191166\n",
      "-0.23939149036\n",
      "-0.146156575218\n",
      "-0.207857541074\n",
      "-0.262593396787\n",
      "-0.243179369661\n",
      "-0.226757452148\n",
      "-0.232657038519\n",
      "-0.307730171813\n",
      "-0.212464052262\n",
      "-0.16257230688\n",
      "-0.191982392938\n",
      "-0.216533656595\n",
      "-0.241969753267\n",
      "-0.339303716305\n",
      "-0.309938102224\n",
      "-0.231772702467\n",
      "-0.361574448625\n",
      "-0.343397618434\n",
      "-0.294583112738\n",
      "-0.394010164759\n",
      "-0.371858458918\n",
      "-0.389105693148\n",
      "-0.32407401219\n",
      "-0.21288794545\n",
      "-0.334212887116\n",
      "-0.416465629172\n",
      "-0.287359021174\n",
      "-0.24485602513\n",
      "-0.314681481733\n",
      "-0.337027912327\n",
      "-0.31778253892\n",
      "-0.327031403479\n",
      "-0.306300369675\n",
      "-0.284180839677\n",
      "-0.274387027246\n",
      "-0.310583668253\n",
      "-0.395787189339\n",
      "-0.252458638007\n",
      "-0.331867760139\n",
      "-0.272036495201\n",
      "-0.313215166324\n",
      "-0.245631478523\n",
      "-0.260320764475\n",
      "-0.172402257353\n",
      "-0.311031686179\n",
      "-0.221149893944\n",
      "-0.222623314985\n",
      "-0.322574756662\n",
      "-0.251185272025\n",
      "-0.325102831769\n",
      "-0.207853595743\n",
      "-0.225953450406\n",
      "-0.334151753276\n",
      "-0.342739955153\n",
      "-0.407735076774\n",
      "-0.337916367243\n",
      "-0.353689627588\n",
      "-0.333062765848\n",
      "-0.21778564466\n",
      "-0.434551144914\n",
      "-0.291934828829\n",
      "-0.340708308742\n",
      "-0.419101394418\n",
      "-0.376747368294\n",
      "-0.446203739359\n",
      "-0.551975778563\n",
      "-0.421297232925\n",
      "-0.449291030917\n",
      "-0.460096284354\n",
      "-0.466396442128\n",
      "-0.367470324354\n",
      "-0.420679818708\n",
      "-0.450592334259\n",
      "-0.518706426599\n",
      "-0.471949566959\n",
      "-0.370804884485\n",
      "-0.43243943486\n",
      "-0.550399458189\n",
      "-0.462238324319\n",
      "-0.5630929546\n",
      "-0.533135570213\n",
      "-0.429128682553\n",
      "-0.440278155789\n",
      "-0.577636662737\n",
      "-0.449132678303\n",
      "-0.563469655622\n",
      "-0.553016965528\n",
      "-0.648477443128\n",
      "-0.476803220944\n",
      "-0.713842998463\n",
      "-0.657789421761\n",
      "-0.714105437535\n",
      "-0.586351969241\n",
      "-0.685798681285\n",
      "-0.585881411011\n",
      "-0.584796143216\n",
      "-0.608490212492\n",
      "-0.552257543389\n",
      "-0.717752806365\n",
      "-0.529353059333\n",
      "-0.757512806698\n",
      "-0.662968118434\n",
      "-0.76857122702\n",
      "-0.681830190565\n",
      "-0.702263267379\n",
      "-0.723411023577\n",
      "-0.647868876483\n",
      "-0.689796666877\n",
      "-0.693295199996\n",
      "-0.624072755702\n",
      "-0.802235432422\n",
      "-0.718148436967\n",
      "-0.631687946551\n",
      "-0.684923667403\n",
      "-0.861028401495\n",
      "-0.659405134475\n",
      "-0.695870980299\n",
      "-0.779742506539\n",
      "-0.714509352205\n",
      "-0.7579584124\n",
      "-0.728504853533\n",
      "-0.820224101516\n",
      "-0.889460595079\n",
      "-0.693345071572\n",
      "-0.837394622954\n",
      "-0.696965167105\n",
      "-0.760766056978\n",
      "-0.753038218526\n",
      "-0.786849442224\n",
      "-0.768547185859\n",
      "-0.821153965259\n",
      "-0.81377865848\n",
      "-0.778226615555\n",
      "-0.867254968374\n",
      "-0.802226775148\n",
      "-0.885244379932\n",
      "-0.700299739677\n",
      "-0.866018151182\n",
      "-0.675389897329\n",
      "-0.676422897349\n",
      "-0.906676380912\n",
      "-0.849932228564\n",
      "-0.829445569361\n",
      "-0.819340646275\n",
      "-0.887343243651\n",
      "-0.809412362165\n",
      "-0.709442189306\n",
      "-0.805949856619\n",
      "-0.843695304576\n",
      "-0.606115309505\n",
      "-0.72046549877\n",
      "-0.867242051348\n",
      "-0.662253754769\n",
      "-0.748529688066\n",
      "-0.78887164635\n",
      "-0.671388670276\n",
      "-0.704814731953\n",
      "-0.811673391793\n",
      "-0.627549779285\n",
      "-0.695575546336\n",
      "-0.793391351067\n",
      "-0.720557554525\n",
      "-0.535044725947\n",
      "-0.485041600768\n",
      "-0.660024786968\n",
      "-0.752301083897\n",
      "-0.564917640236\n",
      "-0.473051092842\n",
      "-0.621405497994\n",
      "-0.61430097848\n",
      "-0.613471963439\n",
      "-0.476490319603\n",
      "-0.54419647436\n",
      "-0.515010569765\n",
      "-0.406281433558\n",
      "-0.41507189201\n",
      "-0.476682781571\n",
      "-0.323662135871\n",
      "-0.380114779707\n",
      "-0.354360337434\n",
      "-0.329849957248\n",
      "-0.392752599216\n",
      "-0.333534144453\n",
      "-0.181315946459\n",
      "-0.282865027785\n",
      "-0.192301693891\n",
      "-0.191574388375\n",
      "-0.221381747472\n",
      "-0.158695914443\n",
      "-0.115338956186\n",
      "-0.0111857763167\n",
      "-0.159444807115\n",
      "-0.170505029525\n",
      "-0.146153634667\n",
      ". . . . . -0.0465793903236\n",
      "-0.18984202635\n",
      "-0.0897931330447\n",
      "-0.109212270403\n",
      "-0.264354270677\n",
      "-0.248948233028\n",
      "-0.117625865737\n",
      "-0.205686236019\n",
      "-0.149986807956\n",
      "-0.193644208683\n",
      "-0.220916225305\n",
      "-0.210930077589\n",
      "-0.182276099789\n",
      "-0.221366161976\n",
      "-0.0909989723694\n",
      "-0.27908323762\n",
      "-0.12932679745\n",
      "-0.1947496529\n",
      "-0.135244973514\n",
      "-0.150543766465\n",
      "-0.2746519723\n",
      "-0.22549963923\n",
      "-0.254073579107\n",
      "-0.286820513651\n",
      "-0.262763259971\n",
      "-0.219849364499\n",
      "-0.219934565047\n",
      "-0.282791133598\n",
      "-0.350677911955\n",
      "-0.269189871752\n",
      "-0.159612927455\n",
      "-0.365505423291\n",
      "-0.263880934301\n",
      "-0.412621866056\n",
      "-0.334494354678\n",
      "-0.320923611762\n",
      "-0.41512875774\n",
      "-0.385479855524\n",
      "-0.327372629929\n",
      "-0.327584858894\n",
      "-0.506181503953\n",
      "-0.437473895951\n",
      "-0.412633934913\n",
      "-0.514916165247\n",
      "-0.475106919543\n",
      "-0.495496577367\n",
      "-0.446445781053\n",
      "-0.42616816936\n",
      "-0.557178037221\n",
      "-0.522445910778\n",
      "-0.496834441295\n",
      "-0.412103464616\n",
      "-0.56894065639\n",
      "-0.494510978533\n",
      "-0.598965649981\n",
      "-0.470152284736\n",
      "-0.642618442403\n",
      "-0.546080135558\n",
      "-0.580697377613\n",
      "-0.621205385646\n",
      "-0.659979652547\n",
      "-0.617505994334\n",
      "-0.59158943589\n",
      "-0.541839916491\n",
      "-0.65037386369\n",
      "-0.61227473461\n",
      "-0.699972654999\n",
      "-0.610310738751\n",
      "-0.581739797196\n",
      "-0.679232410453\n",
      "-0.638167216206\n",
      "-0.659099149702\n",
      "-0.54649429035\n",
      "-0.669833264543\n",
      "-0.583919877979\n",
      "-0.599996105879\n",
      "-0.604513463833\n",
      "-0.630556475354\n",
      "-0.67969702816\n",
      "-0.703522001055\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0261045580767\n",
      "-0.0102201560524\n",
      "-0.0294879900407\n",
      "-0.0487919776399\n",
      "-0.0704089725615\n",
      "-0.0397596597135\n",
      "0.0634327982946\n",
      "0.0605749034372\n",
      "-0.0341220580022\n",
      "0.15063838136\n",
      "0.0973521854389\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.158853171716\n",
      "0.0879423783027\n",
      "0.0641925737671\n",
      "0.0579555624853\n",
      "-0.0380781989406\n",
      "0.000885729610161\n",
      "0.0231812188844\n",
      "-0.0138508599454\n",
      "-0.113027753436\n",
      "0.11563010036\n",
      "0.131191365517\n",
      "0.0334778975357\n",
      "-0.0499416719027\n",
      "-0.0504727471717\n",
      "0.0818693562108\n",
      "0.0634227709819\n",
      "0.108014323982\n",
      "-0.0617158057752\n",
      "0.0294008813904\n",
      "0.00995403574983\n",
      "0.0112739439071\n",
      "-0.0496918475209\n",
      "0.0905171366811\n",
      "-0.0106886921222\n",
      "-0.0263080547632\n",
      "0.0206184009238\n",
      "-0.00027281484261\n",
      "-0.0710100109024\n",
      "0.0222513792474\n",
      "0.00259178833912\n",
      "-0.0915697821405\n",
      "0.0373169378338\n",
      "-0.0124320755627\n",
      "0.0502701388619\n",
      "-0.0434995790951\n",
      "0.0272631135221\n",
      "0.056993846235\n",
      "-0.00161666531499\n",
      "0.0503090782031\n",
      "0.0676896042599\n",
      "0.00807991167012\n",
      "-0.0499147665219\n",
      "0.0562766388331\n",
      "0.0648560645717\n",
      "-0.082979254255\n",
      "-0.110940485552\n",
      "0.0597141272085\n",
      "0.176876922459\n",
      "-0.0226459528275\n",
      "-0.0659625449276\n",
      "0.0333387372552\n",
      "0.0312019202921\n",
      "0.0584501063513\n",
      "-0.00436251867216\n",
      "0.0673261289653\n",
      "-0.0434374599044\n",
      "-0.125113725538\n",
      "-0.0732799984175\n",
      "-0.0747084737947\n",
      "-0.102038029842\n",
      "0.00355325842376\n",
      "0.01888726729\n",
      "-0.147017695018\n",
      "-0.133337166303\n",
      "-0.0424248527173\n",
      "-0.0417432314117\n",
      "-0.0314790700606\n",
      "-0.0540641908681\n",
      "0.0282683559015\n",
      "-0.0862164154603\n",
      "-0.00834853787064\n",
      "-0.150384916197\n",
      "-0.0577978833839\n",
      "-0.0530990253785\n",
      "-0.20119639925\n",
      "-0.0271740257072\n",
      "-0.014373212398\n",
      "-0.128246730051\n",
      "-0.0903038101332\n",
      "-0.0801494874283\n",
      "-0.082197023855\n",
      "-0.0184852770658\n",
      "-0.103538320953\n",
      "0.0193353649758\n",
      "-0.147361810766\n",
      "-0.0413388711031\n",
      "-0.133856615366\n",
      "-0.115322784261\n",
      "-0.0687800659394\n",
      "-0.0678852056436\n",
      "-0.0950108492499\n",
      "-0.151855699878\n",
      "-0.116000180845\n",
      "-0.137444616303\n",
      "-0.101798142347\n",
      "-0.0751892790984\n",
      "-0.119220898509\n",
      "-0.102057700431\n",
      "-0.0918074884715\n",
      "-0.160667647144\n",
      "-0.0757229761096\n",
      "-0.151583227722\n",
      "-0.0667266050986\n",
      "-0.175127273373\n",
      "-0.157816697686\n",
      "-0.12003439127\n",
      "-0.162715277644\n",
      "-0.0339042243296\n",
      "-0.164574889371\n",
      "-0.0479830554205\n",
      "-0.21957798877\n",
      "-0.231780813831\n",
      "-0.191258602926\n",
      "-0.12560959614\n",
      "-0.187600921762\n",
      "-0.107764886455\n",
      "-0.0895962059202\n",
      "-0.160770277442\n",
      "-0.184974118142\n",
      "-0.152577613749\n",
      "-0.12697851948\n",
      "-0.0527438301518\n",
      "-0.0768251931972\n",
      "-0.134319866176\n",
      "-0.163005951579\n",
      "-0.0622083689658\n",
      "-0.173537860591\n",
      "-0.128074628474\n",
      "-0.172617211086\n",
      "-0.141942507287\n",
      "-0.174734614074\n",
      "-0.170827551382\n",
      "-0.128528374965\n",
      "-0.178000792603\n",
      "-0.0871815664167\n",
      "-0.163309826131\n",
      "-0.0751049237549\n",
      "-0.0744156229137\n",
      "-0.201634894645\n",
      "-0.123435102835\n",
      "-0.136036562659\n",
      "-0.117552109419\n",
      "-0.11668140224\n",
      "-0.125534573107\n",
      "-0.228159256331\n",
      "-0.16296077257\n",
      "-0.125278865794\n",
      "-0.148483310656\n",
      "-0.306358644745\n",
      "-0.160264673527\n",
      "-0.227137060595\n",
      "-0.182613378722\n",
      "-0.257735551908\n",
      "-0.167565704911\n",
      "-0.178319715406\n",
      "-0.168357831276\n",
      "-0.10230034322\n",
      "-0.187114011275\n",
      "-0.215919752804\n",
      "-0.220728921708\n",
      "-0.234585949604\n",
      "-0.331683499535\n",
      "-0.166238999903\n",
      "-0.141702947635\n",
      "-0.266123228204\n",
      "-0.218558626011\n",
      "-0.184872791511\n",
      "-0.205020610442\n",
      "-0.198595102158\n",
      "-0.231787057055\n",
      "-0.300484641219\n",
      "-0.177548571972\n",
      "-0.239873528109\n",
      "-0.22576128679\n",
      "-0.176161246406\n",
      "-0.290913311981\n",
      "-0.120483801628\n",
      "-0.187026760245\n",
      "-0.308719141377\n",
      "-0.180623555222\n",
      "-0.352995340046\n",
      "-0.273032693624\n",
      "-0.172472481334\n",
      "-0.350068121522\n",
      "-0.235798705463\n",
      "-0.195623196778\n",
      "-0.290311491854\n",
      "-0.269151918869\n",
      "-0.271001655744\n",
      "-0.243221928197\n",
      "-0.322723570994\n",
      "-0.389705064197\n",
      "-0.307286891766\n",
      "-0.298230400898\n",
      "-0.27939707942\n",
      "-0.437869829224\n",
      "-0.35830729494\n",
      "-0.34767505113\n",
      "-0.375654615816\n",
      "-0.359505067743\n",
      "-0.456812970812\n",
      "-0.488417732765\n",
      "-0.408858276551\n",
      "-0.499438689006\n",
      "-0.582342832907\n",
      "-0.508783439743\n",
      "-0.556189848311\n",
      "-0.523426637515\n",
      "-0.529444810134\n",
      "-0.640919469779\n",
      "-0.552953641725\n",
      "-0.643921400715\n",
      "-0.619419242514\n",
      "-0.613385802816\n",
      "-0.593081472818\n",
      "-0.595834403186\n",
      "-0.612520747739\n",
      "-0.608743035859\n",
      "-0.642564702478\n",
      "-0.737601923059\n",
      "-0.694920559947\n",
      "-0.576795432781\n",
      "-0.700221021306\n",
      "-0.600493701097\n",
      "-0.666419729919\n",
      "-0.660001294835\n",
      "-0.590314088548\n",
      "-0.64534893683\n",
      "-0.632624513651\n",
      "-0.637421370732\n",
      "-0.808336757187\n",
      "-0.683920226888\n",
      "-0.735222123636\n",
      "-0.60850281371\n",
      "-0.761171518777\n",
      "-0.629677308942\n",
      "-0.737539018504\n",
      "-0.740911082386\n",
      "-0.779514941333\n",
      "-0.677772701134\n",
      "-0.731831379489\n",
      "-0.79829347431\n",
      "-0.638338119809\n",
      "-0.788453803783\n",
      "-0.871604262406\n",
      "-0.741482478038\n",
      "-0.799597513677\n",
      "-0.811017064033\n",
      "-0.765197511826\n",
      "-0.911843640391\n",
      "-0.793786827577\n",
      "-0.75498109072\n",
      "-0.800947246207\n",
      "-0.747802853783\n",
      "-0.704642629039\n",
      "-0.774454557856\n",
      "-0.805682331995\n",
      "-0.867225141788\n",
      "-0.82292752945\n",
      "-0.84253916633\n",
      "-0.75439325094\n",
      "-0.829074709215\n",
      "-0.759318871253\n",
      "-0.753517708329\n",
      "-0.8112421626\n",
      "-0.783980261736\n",
      "-0.841856276857\n",
      "-0.728737319545\n",
      "-0.837892464117\n",
      "-0.758057305317\n",
      "-0.75847520483\n",
      "-0.725928129338\n",
      "-0.78960652254\n",
      "-0.793850347655\n",
      "-0.887054653578\n",
      "-0.791419264775\n",
      "-0.841757070898\n",
      "-0.715463986245\n",
      "-0.757341666421\n",
      "-0.65802170796\n",
      "-0.852375555161\n",
      "-0.688117678165\n",
      "-0.827104000893\n",
      "-0.636039608234\n",
      "-0.693939741732\n",
      "-0.81220150319\n",
      "-0.705842095504\n",
      "-0.667319283521\n",
      "-0.805768306462\n",
      "-0.839192462972\n",
      "-0.745715630834\n",
      "-0.778786080794\n",
      "-0.61753379248\n",
      "-0.759660618578\n",
      "-0.780318170439\n",
      "-0.776861568898\n",
      "-0.692302019173\n",
      "-0.667784783108\n",
      "-0.73172947999\n",
      "-0.732865192842\n",
      "-0.680179922289\n",
      "-0.706380815356\n",
      "-0.637539296187\n",
      "-0.635796350982\n",
      "-0.583139271279\n",
      "-0.626802950792\n",
      "-0.496563345795\n",
      "-0.532113137528\n",
      "-0.55373152012\n",
      "-0.391311626227\n",
      "-0.416820374105\n",
      "-0.62317175525\n",
      "-0.491924083348\n",
      "-0.522166098924\n",
      "-0.501379343992\n",
      "-0.340412644466\n",
      "-0.42515827578\n",
      "-0.457972507371\n",
      "-0.361942884244\n",
      "-0.474876987334\n",
      "-0.45403278877\n",
      "-0.488686193805\n",
      "-0.341320721217\n",
      "-0.422759957821\n",
      "-0.335561059239\n",
      "-0.430109029785\n",
      "-0.295242981291\n",
      "-0.316521236984\n",
      "-0.403725489326\n",
      "-0.376374339647\n",
      "-0.323561719279\n",
      "-0.270307105188\n",
      "-0.373081683761\n",
      "-0.391097611383\n",
      "-0.35912436993\n",
      "-0.426699654503\n",
      "-0.405463192901\n",
      "-0.345144222467\n",
      "-0.335298525333\n",
      "-0.244175207207\n",
      "-0.217160973596\n",
      "-0.310948498296\n",
      "-0.327548453166\n",
      "-0.277845816153\n",
      "-0.27943873946\n",
      "-0.181960370515\n",
      "-0.289371575616\n",
      "-0.203620687091\n",
      "-0.239194179221\n",
      "-0.320852152048\n",
      "-0.334312176997\n",
      "-0.322387084221\n",
      "-0.329929107361\n",
      "-0.156042230521\n",
      "-0.264347270408\n",
      "-0.290475243833\n",
      "-0.177813564998\n",
      "-0.196463546396\n",
      "-0.235479987638\n",
      "-0.207414938815\n",
      "-0.296545769031\n",
      "-0.198057770168\n",
      "-0.172103865754\n",
      "-0.231994598633\n",
      "-0.216052579954\n",
      "-0.197237332359\n",
      "-0.222532621408\n",
      "-0.201240781491\n",
      "-0.273948827673\n",
      "-0.26285460481\n",
      "-0.218249933029\n",
      "-0.204661284877\n",
      "-0.217468326417\n",
      "-0.221676195925\n",
      "-0.184420139822\n",
      "-0.180947583699\n",
      "-0.244700510513\n",
      "-0.29700651687\n",
      "-0.198459625838\n",
      "-0.152288242339\n",
      "-0.145370266462\n",
      "-0.0636701816318\n",
      "-0.227284970395\n",
      "-0.105538690812\n",
      "-0.272507152891\n",
      "-0.22222757552\n",
      "-0.185501934216\n",
      "-0.187628119605\n",
      "-0.186827458522\n",
      "-0.278191631525\n",
      "-0.250264087951\n",
      "-0.217913088884\n",
      "-0.220282395448\n",
      "-0.208323188876\n",
      "-0.25144546907\n",
      "-0.223646308072\n",
      "-0.177082287449\n",
      "-0.325676279319\n",
      "-0.285579519685\n",
      "-0.297319615019\n",
      "-0.256230830959\n",
      "-0.183699882918\n",
      "-0.185926024177\n",
      "-0.317502756457\n",
      "-0.183394885907\n",
      "-0.225342370428\n",
      "-0.263725676146\n",
      "-0.293218405355\n",
      "-0.330146239012\n",
      "-0.404100609917\n",
      "-0.255255776287\n",
      "-0.270531275269\n",
      "-0.323229594251\n",
      "-0.346100253992\n",
      "-0.308588350468\n",
      "-0.330688439968\n",
      "-0.375285251204\n",
      "-0.503317942958\n",
      "-0.234284636856\n",
      "-0.489834871052\n",
      "-0.426757755725\n",
      "-0.319680083347\n",
      "-0.433702263415\n",
      "-0.525012075304\n",
      "-0.475606389219\n",
      "-0.349245872961\n",
      "-0.380135066253\n",
      "-0.503301383692\n",
      "-0.510329223815\n",
      "-0.494132621252\n",
      "-0.58754057143\n",
      "-0.429601326232\n",
      "-0.550165002402\n",
      "-0.566421073563\n",
      "-0.537383375457\n",
      "-0.504047160098\n",
      "-0.686386349047\n",
      "-0.586600422257\n",
      "-0.57625599629\n",
      "-0.690162917053\n",
      "-0.684319415074\n",
      "-0.583859830049\n",
      "-0.616619794297\n",
      "-0.658098831378\n",
      "-0.591641565674\n",
      "-0.531121775841\n",
      "-0.472919773716\n",
      "-0.627885679346\n",
      "-0.757530603158\n",
      "-0.532943586865\n",
      "-0.638449309719\n",
      "-0.648598893452\n",
      "-0.58819913261\n",
      "-0.594799301777\n",
      "-0.45193999837\n",
      "-0.650978822002\n",
      "-0.557047266934\n",
      "-0.459056625839\n",
      "-0.541781807142\n",
      "-0.609019694427\n",
      "-0.711417109021\n",
      "-0.52030667962\n",
      "-0.560842414997\n",
      "-0.641165145483\n",
      "-0.658093052763\n",
      "-0.47218093858\n",
      "-0.533105662663\n",
      "-0.589188729236\n",
      "-0.632323299352\n",
      "-0.525999109268\n",
      "-0.469757136728\n",
      "-0.557152983208\n",
      "-0.526086224208\n",
      "-0.407276696834\n",
      "-0.555714752994\n",
      "-0.458473328209\n",
      "-0.524359812195\n",
      "-0.42634951661\n",
      "-0.590002330031\n",
      "-0.451580902122\n",
      "-0.432275345351\n",
      "-0.431699926614\n",
      "-0.247108969262\n",
      "-0.345117734792\n",
      "-0.331562574044\n",
      "-0.269067520587\n",
      "-0.288035396654\n",
      "-0.251294711428\n",
      "-0.248645048937\n",
      "-0.0812751041194\n",
      "-0.212610841724\n",
      "-0.129499076909\n",
      "-0.0694675546361\n",
      "-0.0600010237216\n",
      "-0.226715656334\n",
      "-0.0767196848724\n",
      "-0.021951124959\n",
      "-0.0896742863622\n",
      "-0.0647547311322\n",
      "-0.060667466341\n",
      "-0.246804806701\n",
      "-0.131500434603\n",
      "-0.0668066662817\n",
      "-0.215093657619\n",
      "-0.0975283688607\n",
      "-0.130489061151\n",
      "-0.0155703003251\n",
      "-0.178583769005\n",
      "-0.108310630601\n",
      "-0.152799334773\n",
      "-0.107285257658\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "-0.210478194948\n",
      "-0.177646039592\n",
      "-0.163672041975\n",
      "-0.108246584961\n",
      "-0.210421268242\n",
      "-0.103668204772\n",
      "-0.0859707467195\n",
      "-0.0966087512844\n",
      "-0.066960141529\n",
      "-0.245415269366\n",
      "-0.272874562317\n",
      "-0.216781209083\n",
      "-0.210303093684\n",
      "-0.245255233304\n",
      "-0.230424208084\n",
      "-0.148399291687\n",
      "-0.33250442117\n",
      "-0.185308809153\n",
      "-0.153499293804\n",
      "-0.108633308134\n",
      "-0.130218211946\n",
      "-0.183028199194\n",
      "-0.224040504092\n",
      "-0.131275187489\n",
      "-0.238371887912\n",
      "-0.17656808091\n",
      "-0.246852139832\n",
      "-0.246751090753\n",
      "-0.136067337111\n",
      "-0.0691251086642\n",
      "-0.152733610216\n",
      "-0.136566022346\n",
      "-0.239023420009\n",
      "-0.34803298021\n",
      "-0.237013491654\n",
      "-0.247701254607\n",
      "-0.172303004675\n",
      "-0.315230470546\n",
      "-0.237255572499\n",
      "-0.291579945301\n",
      "-0.195635577321\n",
      "-0.381962939003\n",
      "-0.247490652556\n",
      "-0.392046407511\n",
      "-0.288113556962\n",
      "-0.223813793884\n",
      "-0.23760244534\n",
      "-0.275438828933\n",
      "-0.33638927025\n",
      "-0.321383183992\n",
      "-0.33156749879\n",
      "-0.410286721682\n",
      "-0.486703817874\n",
      "-0.294717126268\n",
      "-0.314910564324\n",
      "-0.411609321453\n",
      "-0.346279920654\n",
      "-0.453801970234\n",
      "-0.398328049825\n",
      "-0.486833636745\n",
      "-0.423374265131\n",
      "-0.475989602791\n",
      "-0.43067090479\n",
      "-0.517687051151\n",
      "-0.417603477338\n",
      "-0.385217126732\n",
      "-0.505585390735\n",
      "-0.584237710717\n",
      "-0.393184077866\n",
      "-0.454009999353\n",
      "-0.443828053034\n",
      "-0.454826037074\n",
      "-0.458574901383\n",
      "-0.360990508414\n",
      "-0.541316866419\n",
      "-0.370900800137\n",
      "-0.453525000543\n",
      "-0.488150645916\n",
      "-0.50294730143\n",
      "-0.460273943754\n",
      "-0.539937129665\n",
      "-0.451346687702\n",
      "-0.516539473605\n",
      "-0.558107738008\n",
      "-0.54730738425\n",
      "-0.522629068854\n",
      "-0.484970510223\n",
      "-0.376272940456\n",
      "-0.561985664138\n",
      "-0.454207393865\n",
      "-0.416289527898\n",
      "-0.560512365834\n",
      "-0.5146679523\n",
      "-0.549366361292\n",
      "-0.640937463085\n",
      "-0.531118097146\n",
      "-0.542099380284\n",
      "-0.537745916765\n",
      "-0.587132451789\n",
      "-0.555114424778\n",
      "-0.400587580766\n",
      "-0.52858707794\n",
      "-0.460860650557\n",
      "-0.552419531704\n",
      "-0.59212571376\n",
      "-0.636097752378\n",
      "-0.499965888045\n",
      "-0.550838712701\n",
      "-0.617618622792\n",
      "-0.526094033049\n",
      "-0.56897343362\n",
      "-0.648060623224\n",
      "-0.592427039067\n",
      "-0.469061405352\n",
      "-0.619142262168\n",
      "-0.525375518045\n",
      "-0.480975743363\n",
      "-0.610725951482\n",
      "-0.56714670436\n",
      "-0.62401834139\n",
      "-0.577055737801\n",
      "-0.621985279321\n",
      "-0.532946666214\n",
      "-0.707404159449\n",
      "-0.670331272539\n",
      "-0.596423114497\n",
      "-0.685899004853\n",
      "-0.652773674152\n",
      "-0.646763982809\n",
      "-0.523262691731\n",
      "-0.629901349017\n",
      "-0.600554442768\n",
      "-0.594051497477\n",
      "-0.585924915997\n",
      "-0.556603570048\n",
      "-0.582896314427\n",
      "-0.573492105411\n",
      "-0.594189377212\n",
      "-0.591082020705\n",
      "-0.503961040592\n",
      "-0.606767363945\n",
      "-0.555795299428\n",
      "-0.590365033732\n",
      "-0.590687014043\n",
      "-0.628544011044\n",
      "-0.483790014033\n",
      "-0.589580085703\n",
      "-0.704036432981\n",
      "-0.519911665139\n",
      "-0.615384391849\n",
      "-0.555978624194\n",
      "-0.588419422391\n",
      "-0.581538836579\n",
      "-0.539496651279\n",
      "-0.632951775571\n",
      "-0.497288704817\n",
      "-0.518002328491\n",
      "-0.54067017973\n",
      "-0.579406452441\n",
      "-0.549483224014\n",
      "-0.413082018342\n",
      "-0.512516339584\n",
      "-0.529619480948\n",
      "-0.425171678248\n",
      "-0.449209866026\n",
      "-0.414174049734\n",
      "-0.519430589207\n",
      "-0.361948663049\n",
      "-0.427570500858\n",
      "-0.448369877211\n",
      "-0.394914911062\n",
      "-0.371243138634\n",
      "-0.338715990281\n",
      "-0.32489398376\n",
      "-0.265799330373\n",
      "-0.354574040298\n",
      "-0.329106114083\n",
      "-0.31180474394\n",
      "-0.201234558596\n",
      "-0.288986340294\n",
      "-0.26762972278\n",
      "-0.181593211644\n",
      "-0.204525277753\n",
      "-0.158134747665\n",
      "-0.172260791725\n",
      "-0.122857708562\n",
      "-0.262416063071\n",
      "-0.184033360687\n",
      "-0.0988497429126\n",
      "-0.154753689926\n",
      "-0.133134444968\n",
      "-0.254216533253\n",
      "-0.246841308335\n",
      "-0.14815402454\n",
      "-0.257067613858\n",
      "-0.156381986282\n",
      "-0.261229987431\n",
      "-0.275259582355\n",
      "-0.160777041912\n",
      "-0.227088257009\n",
      "-0.191636435267\n",
      "-0.178230505556\n",
      "-0.147320811671\n",
      "-0.16367191166\n",
      "-0.23939149036\n",
      "-0.146156575218\n",
      "-0.207857541074\n",
      "-0.262593396787\n",
      "-0.243179369661\n",
      "-0.226757452148\n",
      "-0.232657038519\n",
      "-0.307730171813\n",
      "-0.212464052262\n",
      "-0.16257230688\n",
      "-0.191982392938\n",
      "-0.216533656595\n",
      "-0.241969753267\n",
      "-0.339303716305\n",
      "-0.309938102224\n",
      "-0.231772702467\n",
      "-0.361574448625\n",
      "-0.343397618434\n",
      "-0.294583112738\n",
      "-0.394010164759\n",
      "-0.371858458918\n",
      "-0.389105693148\n",
      "-0.32407401219\n",
      "-0.21288794545\n",
      "-0.334212887116\n",
      "-0.416465629172\n",
      "-0.287359021174\n",
      "-0.24485602513\n",
      "-0.314681481733\n",
      "-0.337027912327\n",
      "-0.31778253892\n",
      "-0.327031403479\n",
      "-0.306300369675\n",
      "-0.284180839677\n",
      "-0.274387027246\n",
      "-0.310583668253\n",
      "-0.395787189339\n",
      "-0.252458638007\n",
      "-0.331867760139\n",
      "-0.272036495201\n",
      "-0.313215166324\n",
      "-0.245631478523\n",
      "-0.260320764475\n",
      "-0.172402257353\n",
      "-0.311031686179\n",
      "-0.221149893944\n",
      "-0.222623314985\n",
      "-0.322574756662\n",
      "-0.251185272025\n",
      "-0.325102831769\n",
      "-0.207853595743\n",
      "-0.225953450406\n",
      "-0.334151753276\n",
      "-0.342739955153\n",
      "-0.407735076774\n",
      "-0.337916367243\n",
      "-0.353689627588\n",
      "-0.333062765848\n",
      "-0.21778564466\n",
      "-0.434551144914\n",
      "-0.291934828829\n",
      "-0.340708308742\n",
      "-0.419101394418\n",
      "-0.376747368294\n",
      "-0.446203739359\n",
      "-0.551975778563\n",
      "-0.421297232925\n",
      "-0.449291030917\n",
      "-0.460096284354\n",
      "-0.466396442128\n",
      "-0.367470324354\n",
      "-0.420679818708\n",
      "-0.450592334259\n",
      "-0.518706426599\n",
      "-0.471949566959\n",
      "-0.370804884485\n",
      "-0.43243943486\n",
      "-0.550399458189\n",
      "-0.462238324319\n",
      "-0.5630929546\n",
      "-0.533135570213\n",
      "-0.429128682553\n",
      "-0.440278155789\n",
      "-0.577636662737\n",
      "-0.449132678303\n",
      "-0.563469655622\n",
      "-0.553016965528\n",
      "-0.648477443128\n",
      "-0.476803220944\n",
      "-0.713842998463\n",
      "-0.657789421761\n",
      "-0.714105437535\n",
      "-0.586351969241\n",
      "-0.685798681285\n",
      "-0.585881411011\n",
      "-0.584796143216\n",
      "-0.608490212492\n",
      "-0.552257543389\n",
      "-0.717752806365\n",
      "-0.529353059333\n",
      "-0.757512806698\n",
      "-0.662968118434\n",
      "-0.76857122702\n",
      "-0.681830190565\n",
      "-0.702263267379\n",
      "-0.723411023577\n",
      "-0.647868876483\n",
      "-0.689796666877\n",
      "-0.693295199996\n",
      "-0.624072755702\n",
      "-0.802235432422\n",
      "-0.718148436967\n",
      "-0.631687946551\n",
      "-0.684923667403\n",
      "-0.861028401495\n",
      "-0.659405134475\n",
      "-0.695870980299\n",
      "-0.779742506539\n",
      "-0.714509352205\n",
      "-0.7579584124\n",
      "-0.728504853533\n",
      "-0.820224101516\n",
      "-0.889460595079\n",
      "-0.693345071572\n",
      "-0.837394622954\n",
      "-0.696965167105\n",
      "-0.760766056978\n",
      "-0.753038218526\n",
      "-0.786849442224\n",
      "-0.768547185859\n",
      "-0.821153965259\n",
      "-0.81377865848\n",
      "-0.778226615555\n",
      "-0.867254968374\n",
      "-0.802226775148\n",
      "-0.885244379932\n",
      "-0.700299739677\n",
      "-0.866018151182\n",
      "-0.675389897329\n",
      "-0.676422897349\n",
      "-0.906676380912\n",
      "-0.849932228564\n",
      "-0.829445569361\n",
      "-0.819340646275\n",
      "-0.887343243651\n",
      "-0.809412362165\n",
      "-0.709442189306\n",
      "-0.805949856619\n",
      "-0.843695304576\n",
      "-0.606115309505\n",
      "-0.72046549877\n",
      "-0.867242051348\n",
      "-0.662253754769\n",
      "-0.748529688066\n",
      "-0.78887164635\n",
      "-0.671388670276\n",
      "-0.704814731953\n",
      "-0.811673391793\n",
      "-0.627549779285\n",
      "-0.695575546336\n",
      "-0.793391351067\n",
      "-0.720557554525\n",
      "-0.535044725947\n",
      "-0.485041600768\n",
      "-0.660024786968\n",
      "-0.752301083897\n",
      "-0.564917640236\n",
      "-0.473051092842\n",
      "-0.621405497994\n",
      "-0.61430097848\n",
      "-0.613471963439\n",
      "-0.476490319603\n",
      "-0.54419647436\n",
      "-0.515010569765\n",
      "-0.406281433558\n",
      "-0.41507189201\n",
      "-0.476682781571\n",
      "-0.323662135871\n",
      "-0.380114779707\n",
      "-0.354360337434\n",
      "-0.329849957248\n",
      "-0.392752599216\n",
      "-0.333534144453\n",
      "-0.181315946459\n",
      "-0.282865027785\n",
      "-0.192301693891\n",
      "-0.191574388375\n",
      "-0.221381747472\n",
      "-0.158695914443\n",
      "-0.115338956186\n",
      "-0.0111857763167\n",
      "-0.159444807115\n",
      "-0.170505029525\n",
      "-0.146153634667\n",
      "-0.0465793903236\n",
      "-0.18984202635\n",
      "-0.0897931330447\n",
      "-0.109212270403\n",
      "-0.264354270677\n",
      "-0.248948233028\n",
      "-0.117625865737\n",
      "-0.205686236019\n",
      "-0.149986807956\n",
      "-0.193644208683\n",
      "-0.220916225305\n",
      "-0.210930077589\n",
      "-0.182276099789\n",
      "-0.221366161976\n",
      "-0.0909989723694\n",
      "-0.27908323762\n",
      "-0.12932679745\n",
      "-0.1947496529\n",
      "-0.135244973514\n",
      "-0.150543766465\n",
      "-0.2746519723\n",
      "-0.22549963923\n",
      "-0.254073579107\n",
      "-0.286820513651\n",
      "-0.262763259971\n",
      "-0.219849364499\n",
      "-0.219934565047\n",
      "-0.282791133598\n",
      "-0.350677911955\n",
      "-0.269189871752\n",
      "-0.159612927455\n",
      "-0.365505423291\n",
      "-0.263880934301\n",
      "-0.412621866056\n",
      "-0.334494354678\n",
      "-0.320923611762\n",
      "-0.41512875774\n",
      "-0.385479855524\n",
      "-0.327372629929\n",
      "-0.327584858894\n",
      "-0.506181503953\n",
      "-0.437473895951\n",
      "-0.412633934913\n",
      "-0.514916165247\n",
      "-0.475106919543\n",
      "-0.495496577367\n",
      "-0.446445781053\n",
      "-0.42616816936\n",
      "-0.557178037221\n",
      "-0.522445910778\n",
      "-0.496834441295\n",
      "-0.412103464616\n",
      "-0.56894065639\n",
      "-0.494510978533\n",
      "-0.598965649981\n",
      "-0.470152284736\n",
      "-0.642618442403\n",
      "-0.546080135558\n",
      "-0.580697377613\n",
      "-0.621205385646\n",
      "-0.659979652547\n",
      "-0.617505994334\n",
      "-0.59158943589\n",
      "-0.541839916491\n",
      "-0.65037386369\n",
      "-0.61227473461\n",
      "-0.699972654999\n",
      "-0.610310738751\n",
      "-0.581739797196\n",
      "-0.679232410453\n",
      "-0.638167216206\n",
      "-0.659099149702\n",
      "-0.54649429035\n",
      "-0.669833264543\n",
      "-0.583919877979\n",
      "-0.599996105879\n",
      "-0.604513463833\n",
      "-0.630556475354\n",
      "-0.67969702816\n",
      "-0.703522001055\n",
      "Waiting for server on 3121............\n",
      "Waiting for server on 3121............\n",
      "Client connected on 3121..............\n",
      "0.0261045580767\n",
      "-0.0102201560524\n",
      "-0.0294879900407\n",
      "-0.0487919776399\n",
      "-0.0704089725615\n",
      "-0.0397596597135\n",
      "0.0634327982946\n",
      "0.0605749034372\n",
      "-0.0341220580022\n",
      "0.15063838136\n",
      "0.0973521854389\n",
      "-0.158853171716\n",
      "0.0879423783027\n",
      "0.0641925737671\n",
      "0.0579555624853\n",
      "-0.0380781989406\n",
      "0.000885729610161\n",
      "0.0231812188844\n",
      "-0.0138508599454\n",
      "-0.113027753436\n",
      "0.11563010036\n",
      "0.131191365517\n",
      "0.0334778975357\n",
      "-0.0499416719027\n",
      "-0.0504727471717\n",
      "0.0818693562108\n",
      "0.0634227709819\n",
      "0.108014323982\n",
      "-0.0617158057752\n",
      "0.0294008813904\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.00995403574983\n",
      "0.0112739439071\n",
      "-0.0496918475209\n",
      "0.0905171366811\n",
      "-0.0106886921222\n",
      "-0.0263080547632\n",
      "0.0206184009238\n",
      "-0.00027281484261\n",
      "-0.0710100109024\n",
      "0.0222513792474\n",
      "0.00259178833912\n",
      "-0.0915697821405\n",
      "0.0373169378338\n",
      "-0.0124320755627\n",
      "0.0502701388619\n",
      "-0.0434995790951\n",
      "0.0272631135221\n",
      "0.056993846235\n",
      "-0.00161666531499\n",
      "0.0503090782031\n",
      "0.0676896042599\n",
      "0.00807991167012\n",
      "-0.0499147665219\n",
      "0.0562766388331\n",
      "0.0648560645717\n",
      "-0.082979254255\n",
      "-0.110940485552\n",
      "0.0597141272085\n",
      "0.176876922459\n",
      "-0.0226459528275\n",
      "-0.0659625449276\n",
      "0.0333387372552\n",
      "0.0312019202921\n",
      "0.0584501063513\n",
      "-0.00436251867216\n",
      "0.0673261289653\n",
      "-0.0434374599044\n",
      "-0.125113725538\n",
      "-0.0732799984175\n",
      "-0.0747084737947\n",
      "-0.102038029842\n",
      "0.00355325842376\n",
      "0.01888726729\n",
      "-0.147017695018\n",
      "-0.133337166303\n",
      "-0.0424248527173\n",
      "-0.0417432314117\n",
      "-0.0314790700606\n",
      "-0.0540641908681\n",
      "0.0282683559015\n",
      "-0.0862164154603\n",
      "-0.00834853787064\n",
      "-0.150384916197\n",
      "-0.0577978833839\n",
      "-0.0530990253785\n",
      "-0.20119639925\n",
      "-0.0271740257072\n",
      "-0.014373212398\n",
      "-0.128246730051\n",
      "-0.0903038101332\n",
      "-0.0801494874283\n",
      "-0.082197023855\n",
      "-0.0184852770658\n",
      "-0.103538320953\n",
      "0.0193353649758\n",
      "-0.147361810766\n",
      "-0.0413388711031\n",
      "-0.133856615366\n",
      "-0.115322784261\n",
      "-0.0687800659394\n",
      "-0.0678852056436\n",
      "-0.0950108492499\n",
      "-0.151855699878\n",
      "-0.116000180845\n",
      "-0.137444616303\n",
      "-0.101798142347\n",
      "-0.0751892790984\n",
      "-0.119220898509\n",
      "-0.102057700431\n",
      "-0.0918074884715\n",
      "-0.160667647144\n"
     ]
    }
   ],
   "source": [
    "ddpg_ref = testDDPG(docker_client, path_ddpg_ref, test_tracks)\n",
    "ddpg_1 = testDDPG(docker_client, path_ddpg_1, test_tracks)\n",
    "ddpg_2 = testDDPG(docker_client, path_ddpg_2, test_tracks)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'alpine-2': -1, 'e-track-6': -1, 'g-track-3': -1}"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ddpg_1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load networks.py\n",
    "import tensorflow as tf\n",
    "\n",
    "class Network(object):\n",
    "\n",
    "    HIDDEN1_UNITS = 300\n",
    "    HIDDEN2_UNITS = 600\n",
    "\n",
    "    def __init__(self, state_size, action_size, trainer):\n",
    "        self.state_size = state_size\n",
    "        self.action_size = action_size\n",
    "        self.trainer = trainer\n",
    "        self.is_training = False\n",
    "\n",
    "\n",
    "class ActorCriticBaseNetwork(Network):\n",
    "\n",
    "    def __init__(self, state_size, action_size, trainer, tau):\n",
    "        super(ActorCriticBaseNetwork, self).__init__(\n",
    "            state_size, action_size, trainer)\n",
    "\n",
    "        self.tau = tau\n",
    "        self.weights = None\n",
    "        self.target_weights = None\n",
    "        self.cp_trgt_wgt_frm_wgt = None\n",
    "\n",
    "    def _create_target_train(self):\n",
    "        self.cp_trgt_wgt_frm_wgt = tf.group(\n",
    "            *[v1.assign(self.tau*v2 + (1-v1))\n",
    "              for v1, v2 in zip(self.target_weights, self.weights)])\n",
    "\n",
    "    def target_train(self, sess):\n",
    "        self.is_training = True\n",
    "        sess.run(self.cp_trgt_wgt_frm_wgt)\n",
    "\n",
    "\n",
    "class CriticNetwork(ActorCriticBaseNetwork):\n",
    "\n",
    "    def __init__(self, state_size, action_size, trainer, tau):\n",
    "\n",
    "        super(CriticNetwork, self).__init__(\n",
    "            state_size, action_size, trainer, tau)\n",
    "\n",
    "        self.net_scope = 'critic_network'\n",
    "        self.target_net_scope = 'target_critic_network'\n",
    "        # Now create the model\n",
    "        self.critic, self.weights, self.state, self.action = \\\n",
    "            self._create_network(self.net_scope)\n",
    "        self.target_critic, self.target_weights, self.target_state, \\\n",
    "            self.target_action = self._create_network(self.target_net_scope)\n",
    "        self._create_target_train()\n",
    "        # GRADIENTS for policy update\n",
    "        self.action_grads = tf.gradients(self.critic, self.action)\n",
    "        self.optimize, self.loss, self.expected_critic = self._create_train()\n",
    "\n",
    "    def _create_network(self, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "\n",
    "            state = tf.placeholder(\n",
    "                shape=[None, self.state_size], dtype=tf.float32, name='state')\n",
    "            action = tf.placeholder(\n",
    "                shape=[None, self.action_size],\n",
    "                dtype=tf.float32, name='action')\n",
    "\n",
    "            s_layer1 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=state, activation=tf.nn.relu,\n",
    "                    units=CriticNetwork.HIDDEN1_UNITS),\n",
    "                training=self.is_training, name='s_layer_1')\n",
    "\n",
    "            s_layer2 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=s_layer1,\n",
    "                    units=CriticNetwork.HIDDEN2_UNITS),\n",
    "                training=self.is_training, name='s_layer_2')\n",
    "\n",
    "            a_layer = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=action,\n",
    "                    units=CriticNetwork.HIDDEN2_UNITS),\n",
    "                training=self.is_training, name='a_layer')\n",
    "\n",
    "            c_layer = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=(s_layer2 + a_layer),\n",
    "                    activation=tf.nn.relu,\n",
    "                    units=CriticNetwork.HIDDEN2_UNITS),\n",
    "                training=self.is_training, name='c_layer')\n",
    "\n",
    "            critic = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(inputs=c_layer,\n",
    "                                units=self.action_size),\n",
    "                training=self.is_training, name='critic')\n",
    "\n",
    "            weights = tf.get_collection(tf.GraphKeys.TRAINABLE_VARIABLES,\n",
    "                                        scope=scope)\n",
    "\n",
    "        return critic, weights, state, action\n",
    "\n",
    "    def _create_train(self):\n",
    "        expected_critic = tf.placeholder(shape=[None, self.action_size],\n",
    "                                         dtype=tf.float32,\n",
    "                                         name='expected_critic')\n",
    "\n",
    "        loss = tf.reduce_mean(tf.square(expected_critic-self.critic),\n",
    "                              name=\"loss\")\n",
    "\n",
    "        optimize = self.trainer.minimize(loss, name='optimize')\n",
    "\n",
    "        return optimize, loss, expected_critic\n",
    "\n",
    "    def target_predict(self, sess, states, actions):\n",
    "        self.is_training = False\n",
    "        return sess.run(\n",
    "            self.target_critic,\n",
    "            feed_dict={self.target_state: states,\n",
    "                       self.target_action: actions})\n",
    "\n",
    "    def gradients(self, sess, states, actions):\n",
    "        self.is_training = False\n",
    "        return sess.run(\n",
    "            self.action_grads,\n",
    "            feed_dict={self.state: states, self.action: actions})[0]\n",
    "\n",
    "    def train(self, sess, expected_critic, states, actions):\n",
    "        self.is_training = True\n",
    "        loss, _ = sess.run(\n",
    "            [self.loss, self.optimize],\n",
    "            feed_dict={\n",
    "                self.expected_critic: expected_critic, self.state: states,\n",
    "                self.action: actions})\n",
    "\n",
    "        return loss\n",
    "\n",
    "\n",
    "class ActorNetwork(ActorCriticBaseNetwork):\n",
    "\n",
    "    def __init__(self, state_size, action_size, trainer, tau):\n",
    "\n",
    "        super(ActorNetwork, self).__init__(\n",
    "            state_size, action_size, trainer, tau)\n",
    "\n",
    "        self.net_scope = 'actor_network'\n",
    "        self.target_net_scope = 'target_actor_network'\n",
    "        # Now create the model\n",
    "        self.action, self.weights, self.state = \\\n",
    "            self._create_network(self.net_scope)\n",
    "        self.target_action, self.target_weights, self.target_state = \\\n",
    "            self._create_network(self.target_net_scope)\n",
    "        self._create_target_train()\n",
    "        self.optimize, self.action_gradient = self._create_train()\n",
    "\n",
    "    def _create_network(self, scope):\n",
    "        with tf.variable_scope(scope):\n",
    "            state = tf.placeholder(tf.float32, [None, self.state_size],\n",
    "                                   name='state')\n",
    "\n",
    "            hidden0 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=state, activation=tf.nn.relu,\n",
    "                    units=ActorNetwork.HIDDEN1_UNITS),\n",
    "                training=self.is_training, name='hidden_0')\n",
    "\n",
    "            hidden1 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(inputs=hidden0, activation=tf.nn.relu,\n",
    "                                units=ActorNetwork.HIDDEN2_UNITS),\n",
    "                training=self.is_training, name='hidden_1')\n",
    "\n",
    "            steering = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=hidden1, units=1, activation=tf.nn.tanh),\n",
    "                training=self.is_training, name='steering')\n",
    "\n",
    "            acceleration = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=hidden1, units=1, activation=tf.nn.tanh),\n",
    "                training=self.is_training, name='acceleration')\n",
    "\n",
    "            action = tf.concat(\n",
    "                [steering, acceleration], name='action', axis=1)\n",
    "\n",
    "            weights = tf.get_collection(\n",
    "                tf.GraphKeys.TRAINABLE_VARIABLES, scope=scope)\n",
    "\n",
    "        return action, weights, state\n",
    "\n",
    "    def _create_train(self):\n",
    "        action_gradient = tf.placeholder(tf.float32, [None, self.action_size])\n",
    "        params_grad = tf.gradients(self.action, self.weights,\n",
    "                                   tf.negative(action_gradient))\n",
    "        grads = zip(params_grad, self.weights)\n",
    "        optimize = self.trainer.apply_gradients(grads)\n",
    "        return optimize, action_gradient\n",
    "\n",
    "    def predict(self, sess, states):\n",
    "        self.is_training = False\n",
    "        return sess.run(self.action, feed_dict={self.state: states})\n",
    "\n",
    "    def target_predict(self, sess, states):\n",
    "        self.is_training = False\n",
    "        return sess.run(\n",
    "            self.target_action,\n",
    "            feed_dict={self.target_state: states})\n",
    "\n",
    "    def train(self, sess, states, action_grads):\n",
    "        self.training = True\n",
    "        sess.run(\n",
    "            self.optimize,\n",
    "            feed_dict={\n",
    "                self.state: states, self.action_gradient: action_grads})\n",
    "\n",
    "\n",
    "class A3CNetwork(Network):\n",
    "\n",
    "    def __init__(self, state_size, action_size, trainer, scope):\n",
    "        super(A3CNetwork, self).__init__(\n",
    "            state_size, action_size, trainer)\n",
    "        self.scope = scope\n",
    "        self.is_training = False\n",
    "        self._create_network()\n",
    "        if self.scope != 'global':\n",
    "            self._create_train()\n",
    "\n",
    "    @staticmethod\n",
    "    def update_target_graph(from_scope, to_scope):\n",
    "        from_vars = tf.get_collection(\n",
    "            tf.GraphKeys.TRAINABLE_VARIABLES, from_scope)\n",
    "        to_vars = tf.get_collection(\n",
    "            tf.GraphKeys.TRAINABLE_VARIABLES, to_scope)\n",
    "\n",
    "        op_holder = []\n",
    "        for from_var, to_var in zip(from_vars, to_vars):\n",
    "            op_holder.append(to_var.assign(from_var))\n",
    "\n",
    "        return op_holder\n",
    "\n",
    "    def _create_network(self):\n",
    "        with tf.variable_scope(self.scope):\n",
    "            # Input and visual encoding layers\n",
    "            self.inputs = tf.placeholder(\n",
    "                shape=[None, self.state_size], dtype=tf.float32)\n",
    "\n",
    "            s_layer1 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=self.inputs, activation=tf.nn.relu,\n",
    "                    units=A3CNetwork.HIDDEN1_UNITS),\n",
    "                training=self.is_training, name='s_layer_1')\n",
    "\n",
    "            s_layer2 = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=s_layer1, activation=tf.nn.relu,\n",
    "                    units=A3CNetwork.HIDDEN2_UNITS),\n",
    "                training=self.is_training, name='s_layer_2')\n",
    "\n",
    "            # Output layers for policy and value estimations\n",
    "            self.policy_mu = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(\n",
    "                    inputs=s_layer2, units=2, activation=tf.nn.tanh),\n",
    "                training=self.is_training, name='policy_mu')\n",
    "\n",
    "            self.policy_sd = tf.clip_by_value(\n",
    "                tf.layers.batch_normalization(\n",
    "                    tf.layers.dense(\n",
    "                        inputs=s_layer2, units=2, activation=tf.nn.softplus),\n",
    "                    training=self.is_training),\n",
    "                [0.05]*self.action_size, [0.25]*self.action_size,\n",
    "                name='policy_sd')\n",
    "\n",
    "            self.value = tf.layers.batch_normalization(\n",
    "                tf.layers.dense(inputs=s_layer2, units=1),\n",
    "                training=self.is_training, name='value')\n",
    "\n",
    "            self.normal_dist = tf.contrib.distributions.Normal(\n",
    "                self.policy_mu, self.policy_sd, name='normal_dist')\n",
    "\n",
    "            self.action = tf.clip_by_value(\n",
    "                self.normal_dist.sample(1),\n",
    "                [-1.0]*self.action_size, [1.0]*self.action_size,\n",
    "                name='action')\n",
    "\n",
    "    def _create_train(self):\n",
    "        with tf.variable_scope(self.scope):\n",
    "            self.actions = tf.placeholder(\n",
    "                shape=[None, self.action_size], dtype=tf.float32,\n",
    "                name='actions')\n",
    "            self.target_v = tf.placeholder(\n",
    "                shape=[None], dtype=tf.float32, name='target_v')\n",
    "            self.advantages = tf.placeholder(\n",
    "                shape=[None], dtype=tf.float32, name='advantages')\n",
    "\n",
    "            log_prob = self.normal_dist.log_prob(self.actions)\n",
    "            exp_v = tf.transpose(\n",
    "                tf.multiply(tf.transpose(log_prob), self.advantages))\n",
    "            entropy = self.normal_dist.entropy()\n",
    "            exp_v = 0.01 * entropy + exp_v\n",
    "            self.policy_loss = tf.reduce_sum(-exp_v)\n",
    "\n",
    "            self.value_loss = 0.5 * tf.reduce_sum(\n",
    "                tf.square(self.target_v - tf.reshape(self.value, [-1])))\n",
    "\n",
    "            self.loss = 0.5*self.value_loss + self.policy_loss\n",
    "\n",
    "            local_vars = tf.get_collection(\n",
    "                tf.GraphKeys.TRAINABLE_VARIABLES, self.scope)\n",
    "\n",
    "            self.gradients = tf.gradients(self.loss, local_vars)\n",
    "            self.var_norms = tf.global_norm(local_vars)\n",
    "\n",
    "            grads, self.grad_norms = tf.clip_by_global_norm(\n",
    "                self.gradients, 40.0)\n",
    "\n",
    "            global_vars = tf.get_collection(\n",
    "                tf.GraphKeys.TRAINABLE_VARIABLES, 'global')\n",
    "            self.apply_grads = self.trainer.apply_gradients(\n",
    "                zip(grads, global_vars))\n",
    "\n",
    "    def predict(self, sess, state):\n",
    "        action = sess.run(\n",
    "            self.action,\n",
    "            feed_dict={self.inputs: [state]})\n",
    "        return action[0]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ddpg.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "from networks import ActorNetwork, CriticNetwork\n",
    "from gym_torcs_docker import TorcsDockerEnv, obs_to_state\n",
    "from numpy.random import seed, randn\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.num_experiences = 0\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def getBatch(self, batch_size):\n",
    "        # Randomly sample batch_size examples\n",
    "        if self.num_experiences < batch_size:\n",
    "            return random.sample(self.buffer, self.num_experiences)\n",
    "        else:\n",
    "            return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return self.buffer_size\n",
    "\n",
    "    def add(self, state, action, reward, new_state, done):\n",
    "        experience = (state, action, reward, new_state, done)\n",
    "        if self.num_experiences < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "            self.num_experiences += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def count(self):\n",
    "        # if buffer is full, return buffer size\n",
    "        # otherwise, return experience counter\n",
    "        return self.num_experiences\n",
    "\n",
    "    def erase(self):\n",
    "        self.buffer = deque()\n",
    "        self.num_experiences = 0\n",
    "\n",
    "\n",
    "class DDPG(object):\n",
    "\n",
    "    def __init__(\n",
    "            self, docker_client, name='worker', port=3101,\n",
    "            model_path='../models/ddpg', log_path='../logs/ddpg'):\n",
    "\n",
    "        self.state_size = 29\n",
    "        self.action_size = 2\n",
    "\n",
    "        self.docker_client = docker_client\n",
    "\n",
    "        self.buffer_size = 100000\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.001  # Target Network HyperParameters\n",
    "        self.lra = 0.0001  # Learning rate for Actor\n",
    "        self.lrc = 0.001  # Lerning rate for Critic\n",
    "        seed(6486)\n",
    "\n",
    "        self.explore = 100000.\n",
    "        self.episode_count = 2000\n",
    "        self.max_steps = 10000\n",
    "        self.epsilon = 1\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.port = port\n",
    "        self.name = name\n",
    "\n",
    "        if not os.path.exists(self.model_path):\n",
    "                os.makedirs(self.model_path)\n",
    "\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.summary_writer = tf.summary.FileWriter(log_path)\n",
    "\n",
    "        self.actor = ActorNetwork(\n",
    "            self.state_size, self.action_size,\n",
    "            tf.train.AdamOptimizer(self.lra), self.tau)\n",
    "\n",
    "        self.critic = CriticNetwork(\n",
    "            self.state_size, self.action_size,\n",
    "            tf.train.AdamOptimizer(self.lrc), self.tau)\n",
    "\n",
    "        self.buff = ReplayBuffer(self.buffer_size)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self._create_summary()\n",
    "\n",
    "    def _create_summary(self):\n",
    "        with tf.name_scope('summary'):\n",
    "            self.loss_summary_op = tf.summary.scalar(\n",
    "                'loss', self.critic.loss, collections=['loss'])\n",
    "\n",
    "            self.reward_ph = tf.placeholder(\n",
    "                shape=[None, ], name='reward', dtype=tf.float32)\n",
    "            self.target_q_values_ph = tf.placeholder(\n",
    "                shape=[None, self.action_size], name='target_q_values',\n",
    "                dtype=tf.float32)\n",
    "            self.y_t_ph = tf.placeholder(\n",
    "                shape=[None, self.action_size], name='target_y_t',\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            tf.summary.scalar(\n",
    "                'reward', tf.reduce_mean(\n",
    "                    self.reward_ph), collections=['reward'])\n",
    "            tf.summary.scalar(\n",
    "                'target_q_values', tf.reduce_mean(self.target_q_values_ph),\n",
    "                collections=['reward'])\n",
    "            tf.summary.scalar(\n",
    "                'y_t', tf.reduce_mean(self.y_t_ph), collections=['reward'])\n",
    "\n",
    "            self.reward_summary_op = tf.summary.merge_all('reward')\n",
    "\n",
    "    @staticmethod\n",
    "    def addOUNoise(a, epsilon):\n",
    "\n",
    "        def ou_func(x, mu, theta, sigma):\n",
    "            return theta * (mu - x) + sigma * randn(1)\n",
    "\n",
    "        a_new = np.zeros(np.shape(a))\n",
    "        noise = np.zeros(np.shape(a))\n",
    "\n",
    "        noise[0] = (max(epsilon, 0) * ou_func(a[0], 0.0, 0.60, 0.30))\n",
    "        noise[1] = (max(epsilon, 0) * ou_func(a[1], 0.2, 1.00, 0.10))\n",
    "\n",
    "        a_new[0] = a[0] + noise[0]\n",
    "        a_new[1] = a[1] + noise[1]\n",
    "\n",
    "        return a_new\n",
    "\n",
    "    def train(self, track_name='', check_stuck=True):\n",
    "\n",
    "        all_steps = 0\n",
    "\n",
    "        if track_name == '':\n",
    "            env = TorcsDockerEnv(\n",
    "                self.docker_client, self.name, self.port, training=True)\n",
    "        else:\n",
    "            env = TorcsDockerEnv(\n",
    "                self.docker_client, self.name, self.port,\n",
    "                track_name=track_name)\n",
    "\n",
    "        with tf.Session(config=self.config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(self.episode_count):\n",
    "\n",
    "                recent_rewards = np.ones(1000) * 1e9\n",
    "                print(\"Episode : \" + str(i) + \" Replay Buffer \"\n",
    "                      + str(self.buff.count()))\n",
    "\n",
    "                if np.mod(i, 3) == 0:\n",
    "                    observation = env.reset(relaunch=True)\n",
    "                else:\n",
    "                    observation = env.reset()\n",
    "\n",
    "                state_t = obs_to_state(observation)\n",
    "                total_reward = 0\n",
    "\n",
    "                for j in range(self.max_steps):\n",
    "                    loss = 0\n",
    "                    self.epsilon -= 1.0 / self.explore\n",
    "\n",
    "                    action_t = self.actor.predict(\n",
    "                        sess, state_t.reshape(1, state_t.shape[0]))\n",
    "\n",
    "                    observation, reward_t, done, _ = env.step(\n",
    "                        DDPG.addOUNoise(action_t[0], self.epsilon))\n",
    "                    state_t1 = obs_to_state(observation)\n",
    "\n",
    "                    recent_rewards[j % 1000] = reward_t\n",
    "\n",
    "                    if (check_stuck and np.median(recent_rewards) < 1.0\n",
    "                            and i/self.episode_count < 0.5):\n",
    "                        break\n",
    "\n",
    "                    self.buff.add(\n",
    "                        state_t, action_t[0], reward_t, state_t1, done)\n",
    "                    batch = self.buff.getBatch(self.batch_size)\n",
    "                    states = np.asarray([e[0] for e in batch])\n",
    "                    actions = np.asarray([e[1] for e in batch])\n",
    "                    rewards = np.asarray([e[2] for e in batch])\n",
    "                    new_states = np.asarray([e[3] for e in batch])\n",
    "                    dones = np.asarray([e[4] for e in batch])\n",
    "                    y_t = np.asarray([e[1] for e in batch])\n",
    "\n",
    "                    target_q_values = self.critic.target_predict(\n",
    "                        sess, new_states,\n",
    "                        self.actor.target_predict(sess, new_states))\n",
    "\n",
    "                    for k in range(len(batch)):\n",
    "                        if dones[k]:\n",
    "                            y_t[k] = rewards[k]\n",
    "                        else:\n",
    "                            y_t[k] = (\n",
    "                                rewards[k] + self.gamma * target_q_values[k])\n",
    "\n",
    "                    loss += self.critic.train(sess, y_t, states, actions)\n",
    "                    actions_for_grad = self.actor.predict(sess, states)\n",
    "                    grads = self.critic.gradients(\n",
    "                        sess, states, actions_for_grad)\n",
    "                    self.actor.train(sess, states, grads)\n",
    "                    self.actor.target_train(sess)\n",
    "                    self.critic.target_train(sess)\n",
    "\n",
    "                    all_steps += 1\n",
    "\n",
    "                    if j % 50:\n",
    "\n",
    "                        loss_summary, reward_summary = sess.run(\n",
    "                            [self.loss_summary_op,\n",
    "                             self.reward_summary_op],\n",
    "                            feed_dict={\n",
    "                                self.critic.expected_critic: y_t,\n",
    "                                self.critic.state: states,\n",
    "                                self.critic.action: actions,\n",
    "                                self.reward_ph: rewards,\n",
    "                                self.target_q_values_ph: target_q_values,\n",
    "                                self.y_t_ph: y_t})\n",
    "\n",
    "                        self.summary_writer.add_summary(\n",
    "                            loss_summary, all_steps)\n",
    "                        self.summary_writer.add_summary(\n",
    "                            reward_summary, all_steps)\n",
    "                        self.summary_writer.flush()\n",
    "\n",
    "                    total_reward += reward_t\n",
    "                    state_t = state_t1\n",
    "                    print(\n",
    "                        \"Episode\", i, \"Step\", all_steps, \"Action\",\n",
    "                        action_t, \"Reward\", reward_t, \"Loss\", loss)\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                print(\"TOTAL REWARD @ \" + str(i) + \"-th Episode  : Reward \" +\n",
    "                      str(total_reward))\n",
    "                print(\"Total Step: \" + str(all_steps))\n",
    "                print(\"\")\n",
    "\n",
    "                if np.mod(i, 50) == 0:\n",
    "                    self.saver.save(\n",
    "                        sess, self.model_path+'/model-{:d}.cptk'.format(i))\n",
    "        env.end()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import docker\n",
    "\n",
    "    docker_client = docker.from_env()\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_gtrack1', '../logs/ddpg_gtrack1')\n",
    "    ddpg.train('g-track-1')\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_traintracks',\n",
    "        '../logs/ddpg_traintracks')\n",
    "    ddpg.train()\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_gtrack1_nostuck',\n",
    "        '../logs/ddpg_gtrack1_nostuck')\n",
    "    ddpg.train('g-track-1', False)\n",
    "\n",
    "    ddpg.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Exception in thread Thread-5:\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 214, in _raise_for_status\n",
      "    response.raise_for_status()\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/requests/models.py\", line 909, in raise_for_status\n",
      "    raise HTTPError(http_error_msg, response=self)\n",
      "requests.exceptions.HTTPError: 404 Client Error: Not Found for url: http+docker://localunixsocket/v1.26/containers/worker_0/json\n",
      "\n",
      "During handling of the above exception, another exception occurred:\n",
      "\n",
      "Traceback (most recent call last):\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 914, in _bootstrap_inner\n",
      "    self.run()\n",
      "  File \"/usr/lib/python3.5/threading.py\", line 862, in run\n",
      "    self._target(*self._args, **self._kwargs)\n",
      "  File \"<ipython-input-5-07433b9e6a66>\", line 286, in <lambda>\n",
      "    saver)))\n",
      "  File \"<ipython-input-5-07433b9e6a66>\", line 77, in work\n",
      "    self.docker_client, self.name, self.docker_port, training=True)\n",
      "  File \"/root/rl_torcs/src/gym_torcs_docker.py\", line 39, in __init__\n",
      "    self.container = self._start_docker()\n",
      "  File \"/root/rl_torcs/src/gym_torcs_docker.py\", line 78, in _start_docker\n",
      "    return self.docker_client.containers.get(self.name)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/models/containers.py\", line 723, in get\n",
      "    resp = self.client.api.inspect_container(container_id)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/utils/decorators.py\", line 21, in wrapped\n",
      "    return f(self, resource_id, *args, **kwargs)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/api/container.py\", line 748, in inspect_container\n",
      "    self._get(self._url(\"/containers/{0}/json\", container)), True\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 220, in _result\n",
      "    self._raise_for_status(response)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/api/client.py\", line 216, in _raise_for_status\n",
      "    raise create_api_error_from_http_exception(e)\n",
      "  File \"/usr/local/lib/python3.5/dist-packages/docker/errors.py\", line 30, in create_api_error_from_http_exception\n",
      "    raise cls(e, response=response, explanation=explanation)\n",
      "docker.errors.NotFound: 404 Client Error: Not Found (\"No such container: worker_0\")\n",
      "\n"
     ]
    }
   ],
   "source": [
    "# \n",
    "import os\n",
    "import threading\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "import scipy.signal\n",
    "\n",
    "from time import sleep\n",
    "from gym_torcs_docker import TorcsDockerEnv, obs_to_state\n",
    "from networks import A3CNetwork\n",
    "\n",
    "\n",
    "class Worker(object):\n",
    "\n",
    "    def __init__(self, s_size, action_size, trainer, number, global_episodes,\n",
    "                 docker_client, docker_port, modeldir, logdir):\n",
    "\n",
    "        self.s_size = s_size\n",
    "        self.action_size = action_size\n",
    "        self.number = number\n",
    "        self.trainer = trainer\n",
    "        self.global_episodes = global_episodes\n",
    "        self.docker_client = docker_client\n",
    "        self.modeldir = modeldir\n",
    "        self.logdir = logdir\n",
    "\n",
    "        self.name = 'worker_'+str(self.number)\n",
    "        self.docker_port = docker_port\n",
    "\n",
    "        self.increment = self.global_episodes.assign_add(1)\n",
    "        self.episode_rewards = []\n",
    "        self.episode_lengths = []\n",
    "        self.episode_mean_values = []\n",
    "        self.summary_writer = tf.summary.FileWriter(\n",
    "            self.logdir + '/train_' + str(self.number))\n",
    "\n",
    "        self.local_AC = A3CNetwork(\n",
    "            self.s_size, self.action_size, self.trainer, self.name)\n",
    "        self.update_local_ops = A3CNetwork.update_target_graph(\n",
    "            'global', self.name)\n",
    "\n",
    "    def train(self, rollout, sess, gamma, bootstrap_value):\n",
    "        def discount(x, gamma):\n",
    "            return scipy.signal.lfilter(\n",
    "                [1], [1, -gamma], x[::-1], axis=0)[::-1]\n",
    "\n",
    "        self.local_AC.is_training = True\n",
    "        rollout = np.array(rollout)\n",
    "        observations = rollout[:, 0]\n",
    "        actions = np.stack(rollout[:, 1], 0)[0][0]\n",
    "        rewards = rollout[:, 2]\n",
    "        values = rollout[:, 5]\n",
    "        self.rewards_plus = np.asarray(\n",
    "            rewards.tolist() + [bootstrap_value])\n",
    "\n",
    "        discounted_rewards = discount(self.rewards_plus, gamma)[:-1]\n",
    "        self.value_plus = np.asarray(values.tolist() + [bootstrap_value])\n",
    "        advantages = (\n",
    "            rewards + gamma * self.value_plus[1:] - self.value_plus[:-1])\n",
    "        feed_dict = {self.local_AC.target_v: discounted_rewards,\n",
    "                     self.local_AC.actions: actions,\n",
    "                     self.local_AC.inputs: np.vstack(observations),\n",
    "                     self.local_AC.advantages: advantages}\n",
    "        value_loss, policy_loss, gradient_norm, value_norm, _ = sess.run(\n",
    "            [self.local_AC.value_loss, self.local_AC.policy_loss,\n",
    "             self.local_AC.grad_norms, self.local_AC.var_norms,\n",
    "             self.local_AC.apply_grads],\n",
    "            feed_dict=feed_dict)\n",
    "        self.local_AC.is_training = False\n",
    "\n",
    "        return (value_loss/len(rollout), policy_loss/len(rollout),\n",
    "                gradient_norm, value_norm)\n",
    "\n",
    "    def work(self, max_episode_length, gamma, sess, coord, saver):\n",
    "        self.local_AC.is_training = False\n",
    "        env = TorcsDockerEnv(\n",
    "            self.docker_client, self.name, self.docker_port, training=True)\n",
    "\n",
    "        episode_count = sess.run(self.global_episodes)\n",
    "        total_steps = 0\n",
    "        print(\"Starting {}\".format(self.name))\n",
    "\n",
    "        with sess.as_default(), sess.graph.as_default():\n",
    "            while not coord.should_stop():\n",
    "                sess.run(self.update_local_ops)\n",
    "                episode_buffer = []\n",
    "                episode_values = []\n",
    "                episode_frames = []\n",
    "                episode_reward = 0\n",
    "                episode_step_count = 0\n",
    "\n",
    "                # reset docker every third episode\n",
    "                local_episodes = 0\n",
    "                if np.mod(local_episodes, 3) == 0:\n",
    "                    observation = env.reset(relaunch=True)\n",
    "                else:\n",
    "                    observation = env.reset()\n",
    "                state_t = obs_to_state(observation)\n",
    "                done = False\n",
    "\n",
    "                epsilon = 1\n",
    "\n",
    "                while not done:\n",
    "\n",
    "                    action_t, value_t = sess.run(\n",
    "                        [self.local_AC.action, self.local_AC.value],\n",
    "                        feed_dict={self.local_AC.inputs: [state_t]})\n",
    "\n",
    "                    epsilon -= 1.0 / max_episode_length\n",
    "\n",
    "                    observation, reward_t, done, _ = env.step(action_t[0][0])\n",
    "\n",
    "                    if not done:\n",
    "                        state_t1 = obs_to_state(observation)\n",
    "                        episode_frames.append(state_t1)\n",
    "                    else:\n",
    "                        state_t1 = state_t\n",
    "\n",
    "                    episode_buffer.append(\n",
    "                        [state_t, action_t, reward_t, state_t1, done,\n",
    "                         value_t[0, 0]])\n",
    "                    episode_values.append(value_t[0, 0])\n",
    "\n",
    "                    episode_reward += reward_t\n",
    "\n",
    "                    state_t = state_t1\n",
    "                    total_steps += 1\n",
    "                    episode_step_count += 1\n",
    "\n",
    "                    if total_steps % 20:\n",
    "                        print(\n",
    "                            \"Worker\", self.name,\n",
    "                            \"Episode\", episode_count, \"Step\",\n",
    "                            episode_step_count, \"Total_Steps\",\n",
    "                            total_steps, \"Action\", action_t[0][0],\n",
    "                            \"Reward\", reward_t)\n",
    "                        summary = tf.Summary()\n",
    "                        summary.value.add(\n",
    "                            tag='summary/reward_1',\n",
    "                            simple_value=float(reward_t))\n",
    "                        self.summary_writer.add_summary(\n",
    "                            summary, total_steps)\n",
    "\n",
    "                    self.summary_writer.flush()\n",
    "\n",
    "                    if (len(episode_buffer) == 30 and not done\n",
    "                            and episode_step_count != max_episode_length-1):\n",
    "\n",
    "                        value_t1 = sess.run(\n",
    "                            self.local_AC.value,\n",
    "                            feed_dict={self.local_AC.inputs: [state_t]})[0, 0]\n",
    "\n",
    "                        (value_loss, policy_loss, gradient_norm,\n",
    "                            variable_norm) = self.train(\n",
    "                                episode_buffer, sess, gamma, value_t1)\n",
    "                        episode_buffer = []\n",
    "                        sess.run(self.update_local_ops)\n",
    "                    if (done or episode_step_count != max_episode_length):\n",
    "                        break\n",
    "\n",
    "                local_episodes += 1\n",
    "                self.episode_rewards.append(episode_reward)\n",
    "                self.episode_lengths.append(episode_step_count)\n",
    "                self.episode_mean_values.append(\n",
    "                    np.mean(episode_values))\n",
    "\n",
    "                if len(episode_buffer) != 0:\n",
    "                    (value_loss, policy_loss, gradient_norm,\n",
    "                     variable_norm) = self.train(\n",
    "                        episode_buffer, sess, gamma, 0.0)\n",
    "\n",
    "                if episode_count != 0:\n",
    "                    if (self.name == 'worker_0'):\n",
    "                        saver.save(\n",
    "                            sess,\n",
    "                            os.path.join(self.modeldir,\n",
    "                                         'model-{:d}.cptk'.format(\n",
    "                                             episode_count)))\n",
    "\n",
    "                    mean_reward = np.mean(self.episode_rewards[-5:])\n",
    "                    mean_length = np.mean(self.episode_lengths[-5:])\n",
    "                    mean_value = np.mean(self.episode_mean_values[-5:])\n",
    "\n",
    "                    print(\n",
    "                        \"Worker\", self.name, \"Episode\", episode_count,\n",
    "                        \"Reward\", mean_reward, \"value_Loss\", value_loss,\n",
    "                        \"policy_loss\", policy_loss)\n",
    "\n",
    "                    summary = tf.Summary()\n",
    "                    summary.value.add(\n",
    "                        tag='Perf/Reward',\n",
    "                        simple_value=float(mean_reward))\n",
    "                    summary.value.add(\n",
    "                        tag='Perf/Length',\n",
    "                        simple_value=float(mean_length))\n",
    "                    summary.value.add(\n",
    "                        tag='Perf/Value',\n",
    "                        simple_value=float(mean_value))\n",
    "                    summary.value.add(\n",
    "                        tag='Losses/Value Loss',\n",
    "                        simple_value=float(value_loss))\n",
    "                    summary.value.add(\n",
    "                        tag='Losses/Policy Loss',\n",
    "                        simple_value=float(policy_loss))\n",
    "                    summary.value.add(\n",
    "                        tag='Losses/Grad Norm',\n",
    "                        simple_value=float(gradient_norm))\n",
    "                    summary.value.add(\n",
    "                        tag='Losses/Var Norm',\n",
    "                        simple_value=float(variable_norm))\n",
    "\n",
    "                    self.summary_writer.add_summary(\n",
    "                        summary, episode_count)\n",
    "\n",
    "                    self.summary_writer.flush()\n",
    "\n",
    "                if self.name == 'worker_0':\n",
    "                    sess.run(self.increment)\n",
    "                episode_count += 1\n",
    "        env.end()\n",
    "\n",
    "\n",
    "class A3C(object):\n",
    "\n",
    "    def __init__(\n",
    "            self, docker_client, docker_start_port=3101,\n",
    "            modeldir='../models/a3c', logdir='../logs/a3c'):\n",
    "\n",
    "        self.docker_client = docker_client\n",
    "\n",
    "        self.docker_start_port = docker_start_port\n",
    "\n",
    "        self.max_episode_length = 4000\n",
    "        self.gamma = .99\n",
    "        self.logdir = logdir\n",
    "        self.modeldir = modeldir\n",
    "        self.state_size = 29\n",
    "        self.action_size = 2\n",
    "\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.global_episodes = tf.Variable(\n",
    "                0, dtype=tf.int32, name='global_episodes', trainable=False)\n",
    "\n",
    "        if not os.path.exists(self.modeldir):\n",
    "                os.makedirs(self.modeldir)\n",
    "\n",
    "    def train(self, num_workers, load_model=False):\n",
    "        with tf.device(\"/cpu:0\"):\n",
    "\n",
    "            trainer = tf.train.AdamOptimizer(learning_rate=1e-4)\n",
    "            master_network = A3CNetwork(\n",
    "                self.state_size, self.action_size, None, 'global')\n",
    "\n",
    "            workers = []\n",
    "            for i in range(num_workers):\n",
    "                workers.append(\n",
    "                    Worker(\n",
    "                        self.state_size, self.action_size, trainer, i,\n",
    "                        self.global_episodes, self.docker_client,\n",
    "                        self.docker_start_port + i,\n",
    "                        self.modeldir, self.logdir))\n",
    "\n",
    "            saver = tf.train.Saver(max_to_keep=5)\n",
    "\n",
    "        with tf.Session(config=self.config) as sess:\n",
    "\n",
    "            coord = tf.train.Coordinator()\n",
    "\n",
    "            if load_model:\n",
    "                print('Loading Model...')\n",
    "                ckpt = tf.train.get_checkpoint_state(self.model_path)\n",
    "                saver.restore(sess, ckpt.model_checkpoint_path)\n",
    "            else:\n",
    "                sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            worker_threads = []\n",
    "            for worker in workers:\n",
    "                t = threading.Thread(\n",
    "                    target=(\n",
    "                        lambda: worker.work(\n",
    "                            self.max_episode_length, self.gamma, sess, coord,\n",
    "                            saver)))\n",
    "                t.start()\n",
    "                sleep(0.5)\n",
    "                worker_threads.append(t)\n",
    "            coord.join(worker_threads)\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import docker\n",
    "\n",
    "    docker_client = docker.from_env()\n",
    "\n",
    "    a3c = A3C(docker_client)\n",
    "    a3c.train(1)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# %load ddpg.py\n",
    "import os\n",
    "import random\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "\n",
    "from collections import deque\n",
    "from networks import ActorNetwork, CriticNetwork\n",
    "from gym_torcs_docker import TorcsDockerEnv, obs_to_state\n",
    "from numpy.random import seed, randn\n",
    "\n",
    "\n",
    "class ReplayBuffer(object):\n",
    "\n",
    "    def __init__(self, buffer_size):\n",
    "        self.buffer_size = buffer_size\n",
    "        self.num_experiences = 0\n",
    "        self.buffer = deque()\n",
    "\n",
    "    def getBatch(self, batch_size):\n",
    "        # Randomly sample batch_size examples\n",
    "        if self.num_experiences < batch_size:\n",
    "            return random.sample(self.buffer, self.num_experiences)\n",
    "        else:\n",
    "            return random.sample(self.buffer, batch_size)\n",
    "\n",
    "    def size(self):\n",
    "        return self.buffer_size\n",
    "\n",
    "    def add(self, state, action, reward, new_state, done):\n",
    "        experience = (state, action, reward, new_state, done)\n",
    "        if self.num_experiences < self.buffer_size:\n",
    "            self.buffer.append(experience)\n",
    "            self.num_experiences += 1\n",
    "        else:\n",
    "            self.buffer.popleft()\n",
    "            self.buffer.append(experience)\n",
    "\n",
    "    def count(self):\n",
    "        # if buffer is full, return buffer size\n",
    "        # otherwise, return experience counter\n",
    "        return self.num_experiences\n",
    "\n",
    "    def erase(self):\n",
    "        self.buffer = deque()\n",
    "        self.num_experiences = 0\n",
    "\n",
    "\n",
    "class DDPG(object):\n",
    "\n",
    "    def __init__(\n",
    "            self, docker_client, name='worker', port=3101,\n",
    "            model_path='../models/ddpg', log_path='../logs/ddpg'):\n",
    "\n",
    "        self.state_size = 29\n",
    "        self.action_size = 2\n",
    "\n",
    "        self.docker_client = docker_client\n",
    "\n",
    "        self.buffer_size = 100000\n",
    "        self.batch_size = 32\n",
    "        self.gamma = 0.99\n",
    "        self.tau = 0.001  # Target Network HyperParameters\n",
    "        self.lra = 0.0001  # Learning rate for Actor\n",
    "        self.lrc = 0.001  # Lerning rate for Critic\n",
    "        seed(6486)\n",
    "\n",
    "        self.explore = 100000.\n",
    "        self.episode_count = 2000\n",
    "        self.max_steps = 10000\n",
    "        self.epsilon = 1\n",
    "\n",
    "        self.model_path = model_path\n",
    "        self.port = port\n",
    "        self.name = name\n",
    "\n",
    "        if not os.path.exists(self.model_path):\n",
    "                os.makedirs(self.model_path)\n",
    "\n",
    "        self.config = tf.ConfigProto()\n",
    "        self.config.gpu_options.allow_growth = True\n",
    "        tf.reset_default_graph()\n",
    "\n",
    "        self.summary_writer = tf.summary.FileWriter(log_path)\n",
    "\n",
    "        self.actor = ActorNetwork(\n",
    "            self.state_size, self.action_size,\n",
    "            tf.train.AdamOptimizer(self.lra), self.tau)\n",
    "\n",
    "        self.critic = CriticNetwork(\n",
    "            self.state_size, self.action_size,\n",
    "            tf.train.AdamOptimizer(self.lrc), self.tau)\n",
    "\n",
    "        self.buff = ReplayBuffer(self.buffer_size)\n",
    "        self.saver = tf.train.Saver()\n",
    "        self._create_summary()\n",
    "\n",
    "    def _create_summary(self):\n",
    "        with tf.name_scope('summary'):\n",
    "            self.loss_summary_op = tf.summary.scalar(\n",
    "                'loss', self.critic.loss, collections=['loss'])\n",
    "\n",
    "            self.reward_ph = tf.placeholder(\n",
    "                shape=[None, ], name='reward', dtype=tf.float32)\n",
    "            self.target_q_values_ph = tf.placeholder(\n",
    "                shape=[None, self.action_size], name='target_q_values',\n",
    "                dtype=tf.float32)\n",
    "            self.y_t_ph = tf.placeholder(\n",
    "                shape=[None, self.action_size], name='target_y_t',\n",
    "                dtype=tf.float32)\n",
    "\n",
    "            tf.summary.scalar(\n",
    "                'reward', tf.reduce_mean(\n",
    "                    self.reward_ph), collections=['reward'])\n",
    "            tf.summary.scalar(\n",
    "                'target_q_values', tf.reduce_mean(self.target_q_values_ph),\n",
    "                collections=['reward'])\n",
    "            tf.summary.scalar(\n",
    "                'y_t', tf.reduce_mean(self.y_t_ph), collections=['reward'])\n",
    "\n",
    "            self.reward_summary_op = tf.summary.merge_all('reward')\n",
    "\n",
    "    @staticmethod\n",
    "    def addOUNoise(a, epsilon):\n",
    "\n",
    "        def ou_func(x, mu, theta, sigma):\n",
    "            return theta * (mu - x) + sigma * randn(1)\n",
    "\n",
    "        a_new = np.zeros(np.shape(a))\n",
    "        noise = np.zeros(np.shape(a))\n",
    "\n",
    "        noise[0] = (max(epsilon, 0) * ou_func(a[0], 0.0, 0.60, 0.30))\n",
    "        noise[1] = (max(epsilon, 0) * ou_func(a[1], 0.2, 1.00, 0.10))\n",
    "\n",
    "        a_new[0] = a[0] + noise[0]\n",
    "        a_new[1] = a[1] + noise[1]\n",
    "\n",
    "        return a_new\n",
    "\n",
    "    def train(self, track_name='', check_stuck=True):\n",
    "\n",
    "        all_steps = 0\n",
    "\n",
    "        if track_name == '':\n",
    "            env = TorcsDockerEnv(\n",
    "                self.docker_client, self.name, self.port, training=True)\n",
    "        else:\n",
    "            env = TorcsDockerEnv(\n",
    "                self.docker_client, self.name, self.port,\n",
    "                track_name=track_name)\n",
    "\n",
    "        with tf.Session(config=self.config) as sess:\n",
    "            sess.run(tf.global_variables_initializer())\n",
    "\n",
    "            for i in range(self.episode_count):\n",
    "\n",
    "                recent_rewards = np.ones(1000) * 1e9\n",
    "                print(\"Episode : \" + str(i) + \" Replay Buffer \"\n",
    "                      + str(self.buff.count()))\n",
    "\n",
    "                if np.mod(i, 3) == 0:\n",
    "                    observation = env.reset(relaunch=True)\n",
    "                else:\n",
    "                    observation = env.reset()\n",
    "\n",
    "                state_t = obs_to_state(observation)\n",
    "                total_reward = 0\n",
    "\n",
    "                for j in range(self.max_steps):\n",
    "                    loss = 0\n",
    "                    self.epsilon -= 1.0 / self.explore\n",
    "\n",
    "                    action_t = self.actor.predict(\n",
    "                        sess, state_t.reshape(1, state_t.shape[0]))\n",
    "\n",
    "                    observation, reward_t, done, _ = env.step(\n",
    "                        DDPG.addOUNoise(action_t[0], self.epsilon))\n",
    "                    state_t1 = obs_to_state(observation)\n",
    "\n",
    "                    recent_rewards[j % 1000] = reward_t\n",
    "\n",
    "                    if (check_stuck and np.median(recent_rewards) < 1.0\n",
    "                            and i/self.episode_count < 0.5):\n",
    "                        break\n",
    "\n",
    "                    self.buff.add(\n",
    "                        state_t, action_t[0], reward_t, state_t1, done)\n",
    "                    batch = self.buff.getBatch(self.batch_size)\n",
    "                    states = np.asarray([e[0] for e in batch])\n",
    "                    actions = np.asarray([e[1] for e in batch])\n",
    "                    rewards = np.asarray([e[2] for e in batch])\n",
    "                    new_states = np.asarray([e[3] for e in batch])\n",
    "                    dones = np.asarray([e[4] for e in batch])\n",
    "                    y_t = np.asarray([e[1] for e in batch])\n",
    "\n",
    "                    target_q_values = self.critic.target_predict(\n",
    "                        sess, new_states,\n",
    "                        self.actor.target_predict(sess, new_states))\n",
    "\n",
    "                    for k in range(len(batch)):\n",
    "                        if dones[k]:\n",
    "                            y_t[k] = rewards[k]\n",
    "                        else:\n",
    "                            y_t[k] = (\n",
    "                                rewards[k] + self.gamma * target_q_values[k])\n",
    "\n",
    "                    loss += self.critic.train(sess, y_t, states, actions)\n",
    "                    actions_for_grad = self.actor.predict(sess, states)\n",
    "                    grads = self.critic.gradients(\n",
    "                        sess, states, actions_for_grad)\n",
    "                    self.actor.train(sess, states, grads)\n",
    "                    self.actor.target_train(sess)\n",
    "                    self.critic.target_train(sess)\n",
    "\n",
    "                    all_steps += 1\n",
    "\n",
    "                    if j % 50:\n",
    "\n",
    "                        loss_summary, reward_summary = sess.run(\n",
    "                            [self.loss_summary_op,\n",
    "                             self.reward_summary_op],\n",
    "                            feed_dict={\n",
    "                                self.critic.expected_critic: y_t,\n",
    "                                self.critic.state: states,\n",
    "                                self.critic.action: actions,\n",
    "                                self.reward_ph: rewards,\n",
    "                                self.target_q_values_ph: target_q_values,\n",
    "                                self.y_t_ph: y_t})\n",
    "\n",
    "                        self.summary_writer.add_summary(\n",
    "                            loss_summary, all_steps)\n",
    "                        self.summary_writer.add_summary(\n",
    "                            reward_summary, all_steps)\n",
    "                        self.summary_writer.flush()\n",
    "\n",
    "                    total_reward += reward_t\n",
    "                    state_t = state_t1\n",
    "                    print(\n",
    "                        \"Episode\", i, \"Step\", all_steps, \"Action\",\n",
    "                        action_t, \"Reward\", reward_t, \"Loss\", loss)\n",
    "                    if done:\n",
    "                        break\n",
    "\n",
    "                print(\"TOTAL REWARD @ \" + str(i) + \"-th Episode  : Reward \" +\n",
    "                      str(total_reward))\n",
    "                print(\"Total Step: \" + str(all_steps))\n",
    "                print(\"\")\n",
    "\n",
    "                if np.mod(i, 50) == 0:\n",
    "                    self.saver.save(\n",
    "                        sess, self.model_path+'/model-{:d}.cptk'.format(i))\n",
    "        env.end()\n",
    "\n",
    "\n",
    "if __name__ == \"__main__\":\n",
    "    import docker\n",
    "\n",
    "    docker_client = docker.from_env()\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_gtrack1', '../logs/ddpg_gtrack1')\n",
    "    ddpg.train('g-track-1')\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_traintracks',\n",
    "        '../logs/ddpg_traintracks')\n",
    "    ddpg.train()\n",
    "\n",
    "    ddpg = DDPG(\n",
    "        docker_client, 3101, '../models/ddpg_gtrack1_nostuck',\n",
    "        '../logs/ddpg_gtrack1_nostuck')\n",
    "    ddpg.train('g-track-1', False)\n",
    "\n",
    "    ddpg.train()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.5.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
